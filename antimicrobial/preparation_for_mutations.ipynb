{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'antimicrobial\\\\results\\\\contribs\\\\average_contribs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m contribs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mantimicrobial\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mcontribs\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43maverage_contribs.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m contribs\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'antimicrobial\\\\results\\\\contribs\\\\average_contribs.csv'"
     ]
    }
   ],
   "source": [
    "contribs = pd.read_csv('antimicrobial\\\\results\\\\contribs\\\\average_contribs.csv')\n",
    "contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Position Top 1 Top 2 Top 3 Top 4\n",
      "0          0     C     G     R     L\n",
      "1          1     C     R     K     L\n",
      "2          2     C     G     L     V\n",
      "3          3     C     R     L     K\n",
      "4          4     C     G     L     R\n",
      "5          5     C     G     L     K\n",
      "6          6     C     K     G     L\n",
      "7          7     C     G     L     K\n",
      "8          8     C     L     K     G\n",
      "9          9     C     G     L     K\n",
      "10        10     C     K     A     G\n",
      "11        11     C     G     R     L\n",
      "12        12     C     K     A     G\n",
      "13        13     C     G     R     K\n",
      "14        14     C     K     F     L\n",
      "15        15     C     G     K     A\n",
      "16        16     G     C     I     S\n",
      "17        17     C     K     G     R\n",
      "18        18     C     R     G     F\n",
      "19        19     C     K     G     R\n",
      "20        20     C     G     R     K\n",
      "21        21     C     G     K     L\n",
      "22        22     C     G     L     K\n",
      "23        23     C     R     K     G\n",
      "24        24     C     G     R     L\n",
      "25        25     G     C     L     F\n",
      "26        26     G     F     L     C\n",
      "27        27     C     R     G     F\n",
      "28        28     C     K     G     R\n",
      "29        29     C     F     R     G\n",
      "30        30     C     E     K     G\n",
      "31        31     F     C     A     K\n",
      "32        32     R     C     F     E\n",
      "33        33     C     R     Q     G\n",
      "34        34     C     G     Q     E\n",
      "35        35     C     L     E     M\n",
      "36        36     C     R     E     K\n",
      "37        37     C     S     E     R\n",
      "38        38     E     F     C     G\n",
      "39        39     C     E     D     S\n",
      "40        40     C     F     E     K\n",
      "41        41     C     D     M     F\n",
      "42        42     C     M     E     T\n",
      "43        43     C     M     E     K\n",
      "44        44     C     M     W     E\n",
      "45        45     C     M     D     K\n",
      "46        46     D     C     M     E\n",
      "47        47     C     M     E     F\n",
      "48        48     D     M     C     G\n",
      "49        49     C     G     E     D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "contribs = pd.read_csv('results/contribs/average_contribs.csv')\n",
    "\n",
    "# Initialize a list to store the top 3 amino acids for each position\n",
    "top_amino_acids = []\n",
    "\n",
    "# Iterate through each position (row) in the DataFrame\n",
    "for index, row in contribs.iterrows():\n",
    "    # Get the row as a dictionary and remove the 'Unnamed: 0' key\n",
    "    row_dict = row.to_dict()\n",
    "    del row_dict['Unnamed: 0']\n",
    "    \n",
    "    # Sort the dictionary by values in descending order and get the top 3 items\n",
    "    sorted_amino_acids = sorted(row_dict.items(), key=lambda x: x[1], reverse=True)[:4]\n",
    "    \n",
    "    # Extract only the amino acid names (keys) and add to the list\n",
    "    top_amino_acids.append([index] + [aa[0] for aa in sorted_amino_acids])\n",
    "\n",
    "# Convert the list to a DataFrame for better readability\n",
    "top_amino_acids_df = pd.DataFrame(top_amino_acids, columns=['Position', 'Top 1', 'Top 2', 'Top 3', 'Top 4'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(top_amino_acids_df)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "top_amino_acids_df.to_csv('top_amino_acids.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model/model_layer1_multihead9_fold1_new.pkl'\n",
    "model_eval = Transformer().to(device)\n",
    "# u state dictionaryju su obično pohranjeni weights i biases\n",
    "model_eval.load_state_dict(torch.load(model_file, map_location='cpu'), strict = True)\n",
    "\n",
    "state_dict_keys = model_eval.state_dict().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_sequence(sequence):\n",
    "    print('----------')\n",
    "    top_aa = pd.read_csv('top_amino_acids.csv')\n",
    "    print(top_aa['Top 1'][0])\n",
    "    ls = []\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        seq_list = list(sequence)  # Convert sequence to a list of characters\n",
    "        seq_list[i] = top_aa['Top 1'][i]\n",
    "        mutated_sequence = ''.join(seq_list)  # Join the list back into a string\n",
    "        ls.append(mutated_sequence)\n",
    "        \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "['CEP', 'GCP', 'GEC']\n",
      "tn:\n",
      "       Unnamed: 0                                           sequence  label  \\\n",
      "0              0                                                GEP      0   \n",
      "1              1                                                QHP      0   \n",
      "2              2                                               YLRF      0   \n",
      "3              3                                               FMRF      0   \n",
      "4              9                                               TKPR      0   \n",
      "...          ...                                                ...    ...   \n",
      "5175        9563  MAREGFTLECTSCKMQNYISKKNKKLHPEKVKLSKYCSKCSKHSVH...      0   \n",
      "5176        9564  MISMLRCTFFFVSVILITSYFVTPTMSIKCNRKRHVIKPHICRKIC...      0   \n",
      "5177        9569  MKQTFQPSNRKRKNKHGFRSRMKTINGRRILASRRAKGRKKLTVSD...      0   \n",
      "5178        9570  MGSPEKLRPSDFSKSFLISSIRFAMSFSSFELYSACSSLIRVSSPT...      0   \n",
      "5179        9571  MLLPATMSDKPDMAEIEKFDKSKLKKTETQEKNPLPSKETIEQEKQ...      0   \n",
      "\n",
      "                                                peptide  y_pred  y_prob  \n",
      "0                                                   GEP       0  0.1166  \n",
      "1                                                   QHP       0  0.0842  \n",
      "2                                                  YLRF       0  0.2936  \n",
      "3                                                  FMRF       0  0.4007  \n",
      "4                                                  TKPR       0  0.3111  \n",
      "...                                                 ...     ...     ...  \n",
      "5175  MAREGFTLECTSCKMQNYISKKNKKLHPEKVKLSKYCSKCSKHSVH...       0  0.0034  \n",
      "5176  MISMLRCTFFFVSVILITSYFVTPTMSIKCNRKRHVIKPHICRKIC...       0  0.0420  \n",
      "5177  MKQTFQPSNRKRKNKHGFRSRMKTINGRRILASRRAKGRKKLTVSD...       0  0.0015  \n",
      "5178  MGSPEKLRPSDFSKSFLISSIRFAMSFSSFELYSACSSLIRVSSPT...       0  0.0022  \n",
      "5179  MLLPATMSDKPDMAEIEKFDKSKLKKTETQEKNPLPSKETIEQEKQ...       0  0.0004  \n",
      "\n",
      "[5180 rows x 6 columns]\n",
      "                                                peptide\n",
      "0                                                   GEP\n",
      "1                                                   QHP\n",
      "2                                                  YLRF\n",
      "3                                                  FMRF\n",
      "4                                                  TKPR\n",
      "...                                                 ...\n",
      "5175  MAREGFTLECTSCKMQNYISKKNKKLHPEKVKLSKYCSKCSKHSVH...\n",
      "5176  MISMLRCTFFFVSVILITSYFVTPTMSIKCNRKRHVIKPHICRKIC...\n",
      "5177  MKQTFQPSNRKRKNKHGFRSRMKTINGRRILASRRAKGRKKLTVSD...\n",
      "5178  MGSPEKLRPSDFSKSFLISSIRFAMSFSSFELYSACSSLIRVSSPT...\n",
      "5179  MLLPATMSDKPDMAEIEKFDKSKLKKTETQEKNPLPSKETIEQEKQ...\n",
      "\n",
      "[5180 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "true_negative_samples = pd.read_csv(\"true_negative_samples.csv\")\n",
    "\n",
    "print(mutate_sequence(true_negative_samples['sequence'][0]))\n",
    "\n",
    "print(\"tn:\\n\", true_negative_samples)\n",
    "\n",
    "# print(peptides)\n",
    "predict_data = pd.DataFrame([true_negative_samples['sequence']], index = ['peptide']).T\n",
    "print(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GEP already exists\n",
      "1 QHP already exists\n",
      "2 YLRF already exists\n",
      "3 FMRF already exists\n",
      "4 TKPR already exists\n",
      "5 GFGD already exists\n",
      "6 GFAD already exists\n",
      "7 GSWD already exists\n",
      "8 GTGG already exists\n",
      "9 FFKA already exists\n",
      "10 YMRF already exists\n",
      "11 RYLPT already exists\n",
      "12 YSFGL already exists\n",
      "13 IEFFA already exists\n",
      "14 GTTGT already exists\n",
      "15 FPPWM already exists\n",
      "16 FPPWM already exists\n",
      "17 FVHPM already exists\n",
      "18 FVHPM already exists\n",
      "19 CPPLC already exists\n",
      "20 LPLRF already exists\n",
      "21 VDFFA already exists\n",
      "22 AAAPF already exists\n",
      "23 VGFFT already exists\n",
      "24 MFSPQ already exists\n",
      "25 IEFFT already exists\n",
      "26 NPTNLH already exists\n",
      "27 DPWDWV already exists\n",
      "28 DPWDWV already exists\n",
      "29 VFFAGP already exists\n",
      "30 PIDPGV already exists\n",
      "31 GNFFRF already exists\n",
      "32 PGLGFY already exists\n",
      "33 FVPIWM already exists\n",
      "34 FVPIWM already exists\n",
      "35 IAYKPE already exists\n",
      "36 GSPMFV already exists\n",
      "37 AFSSWG already exists\n",
      "38 RARPRF already exists\n",
      "39 GAPMFV already exists\n",
      "40 QTWLPFV already exists\n",
      "41 YMFHLMD already exists\n",
      "42 YMFHLMD already exists\n",
      "43 FGVLNFF already exists\n",
      "44 GPIPWQR already exists\n",
      "45 GPIPWQR already exists\n",
      "46 QDGPIPP already exists\n",
      "47 IYEPEIA already exists\n",
      "48 IYEPEIA already exists\n",
      "49 AGQNTES already exists\n",
      "50 YAFGYPS already exists\n",
      "51 YAFGYPS already exists\n",
      "52 KMYDFGL already exists\n",
      "53 KNEFIRF already exists\n",
      "54 WREMSVW already exists\n",
      "55 GDPFLRF already exists\n",
      "56 GGKYMRF already exists\n",
      "57 EPYAFGL already exists\n",
      "58 DQVKIVL already exists\n",
      "59 DGYTPRL already exists\n",
      "60 DRNFLRF already exists\n",
      "61 QPWLPFR already exists\n",
      "62 QPWLPFR already exists\n",
      "63 QRWPSPK already exists\n",
      "64 QCGQAWC already exists\n",
      "65 WKEMSVW already exists\n",
      "66 NPYAFGL already exists\n",
      "67 KHEYLRF already exists\n",
      "68 TNDFMRF already exists\n",
      "69 QPWIPFV already exists\n",
      "70 AQSFVRL already exists\n",
      "71 DPYAFGL already exists\n",
      "72 EPNSMWS already exists\n",
      "73 PDNFMRF already exists\n",
      "74 KSAYMRF already exists\n",
      "75 QPWLPFV already exists\n",
      "76 KPNFIRF already exists\n",
      "77 AQSFLRL already exists\n",
      "78 GDNFMRF already exists\n",
      "79 QPWLPFG already exists\n",
      "80 GQDFMRF already exists\n",
      "81 AYNGPLA already exists\n",
      "82 NRNFLRF already exists\n",
      "83 QNWPSPK already exists\n",
      "84 QKKDKKD already exists\n",
      "85 THDFMRF already exists\n",
      "86 WKQMSVW already exists\n",
      "87 AMPMLRL already exists\n",
      "88 SDYLQLAR already exists\n",
      "89 GGPYAFGL already exists\n",
      "90 SPAFNSWG already exists\n",
      "91 GCVLLPWC already exists\n",
      "92 LPLYNFGL already exists\n",
      "93 QTSFTPRL already exists\n",
      "94 MRNYSFGL already exists\n",
      "95 ARPYSFGL already exists\n",
      "96 DASFSSWG already exists\n",
      "97 SPANSVWS already exists\n",
      "98 AGPRFIRF already exists\n",
      "99 GGPYSYGL already exists\n",
      "100 DPAFNSWG already exists\n",
      "101 QKKDKKDK already exists\n",
      "102 APANSVWS already exists\n",
      "103 PDMYAFGL already exists\n",
      "104 AGPYSFGL already exists\n",
      "105 CEHSHDGA already exists\n",
      "106 QVNFSPGW already exists\n",
      "107 DPAFSSWG already exists\n",
      "108 DYMGWMDF already exists\n",
      "109 GLLSGLGL already exists\n",
      "110 RPPGFTPF already exists\n",
      "111 RPPGFTPF already exists\n",
      "112 GCPWDPWC already exists\n",
      "113 GLLAFPRV already exists\n",
      "114 QKKDKKDR already exists\n",
      "115 DPSFNSWG already exists\n",
      "116 GPPYDFGM already exists\n",
      "117 FDAFTTGF already exists\n",
      "118 QLNFSPGW already exists\n",
      "119 SDRNFLRF already exists\n",
      "120 VAAGRPRF already exists\n",
      "121 GAQFSSWG already exists\n",
      "122 LPSIGHYY already exists\n",
      "123 MIKSDQET already exists\n",
      "124 NRPYSFGL already exists\n",
      "125 QNAHPSPK already exists\n",
      "126 QLTFSPDW already exists\n",
      "127 YGGTPPFV already exists\n",
      "128 ADKNFLRF already exists\n",
      "129 SGQYSFGL already exists\n",
      "130 VPPGFTPF already exists\n",
      "131 QVNFTPSW already exists\n",
      "132 MLGFLVLP already exists\n",
      "133 SDMYSFGL already exists\n",
      "134 QLTFTPNW already exists\n",
      "135 MLGFLPLP already exists\n",
      "136 DEVKIVLD already exists\n",
      "137 DPGFSSWG already exists\n",
      "138 GSNDFMRF already exists\n",
      "139 CFIRNCPP already exists\n",
      "140 GADFYSWG already exists\n",
      "141 APPGFTPF already exists\n",
      "142 QVNFSTGW already exists\n",
      "143 QVNFSPNW already exists\n",
      "144 TDRNFLRL already exists\n",
      "145 DQGFNSWG already exists\n",
      "146 QSSFHSWG already exists\n",
      "147 APSLRLRF already exists\n",
      "148 DRPYSFGL already exists\n",
      "149 DASFHSWG already exists\n",
      "150 SRPYSFGL already exists\n",
      "151 MKNSVAEH already exists\n",
      "152 GGNDFMRF already exists\n",
      "153 DPPFAPRM already exists\n",
      "154 GPSAFLRL already exists\n",
      "155 GCVLYPWC already exists\n",
      "156 DPPFSPRL already exists\n",
      "157 RPPGFSPF already exists\n",
      "158 RPPGFSPF already exists\n",
      "159 QLTFTPGW already exists\n",
      "160 ARGYDFGL already exists\n",
      "161 QLNYSPDW already exists\n",
      "162 ADYLQLAR already exists\n",
      "163 SPHYNFGL already exists\n",
      "164 QLNFSPNW already exists\n",
      "165 ASPYAFGL already exists\n",
      "166 VPPKGVSM already exists\n",
      "167 APALRLRF already exists\n",
      "168 SDPNFLRF already exists\n",
      "169 GDRNFLRF already exists\n",
      "170 GCPWMPWC already exists\n",
      "171 AKDNFLRF already exists\n",
      "172 LPVYNFGL already exists\n",
      "173 GCPWDSWC already exists\n",
      "174 GFTPFRIY already exists\n",
      "175 AGPYAFGL already exists\n",
      "176 GSGFSSWG already exists\n",
      "177 TNRNFLRF already exists\n",
      "178 MTASMRLK already exists\n",
      "179 EGDFTPRL already exists\n",
      "180 VERYAFGL already exists\n",
      "181 CHYIFNTC already exists\n",
      "182 QVNFTPGW already exists\n",
      "183 GANDFMRF already exists\n",
      "184 PGQDFMRF already exists\n",
      "185 GCPWEPWC already exists\n",
      "186 CYIQNCPRG already exists\n",
      "187 SQPSMRLRF already exists\n",
      "188 MKKSEDYSS already exists\n",
      "189 QANQDFMRF already exists\n",
      "190 ASLFNAPRV already exists\n",
      "191 TPTAFYGVR already exists\n",
      "192 CCPPVIWCC already exists\n",
      "193 GPETAFFRL already exists\n",
      "194 SADPNFLRF already exists\n",
      "195 APGQDFMRF already exists\n",
      "196 GPETAFLRL already exists\n",
      "197 TSMGFQGVR already exists\n",
      "198 NPQQDFMRF already exists\n",
      "199 QLWATGHFM already exists\n",
      "200 QLWATGHFM already exists\n",
      "201 QGLIPFPRV already exists\n",
      "202 GHADNFMRF already exists\n",
      "203 YSQVARPRF already exists\n",
      "204 LRPDDLSDT already exists\n",
      "205 HGGYKPTDK already exists\n",
      "206 QEYRGWMDF already exists\n",
      "207 QEYRGWMDF already exists\n",
      "208 SEGGQDFWL already exists\n",
      "209 QTLIPMPRL already exists\n",
      "210 SGKPTFIRF already exists\n",
      "211 RQQPFVPRL already exists\n",
      "212 WAGGDASGE already exists\n",
      "213 PFCNAFTGC already exists\n",
      "214 RPPGFDPFR already exists\n",
      "215 GPSGFYGVR already exists\n",
      "216 GYFLFRPRN already exists\n",
      "217 AAGQDFMRF already exists\n",
      "218 GVDSSFLRL already exists\n",
      "219 VPPGFTPFR already exists\n",
      "220 CYIQNCPLG already exists\n",
      "221 CYISNCPQG already exists\n",
      "222 ADYLQLTRA already exists\n",
      "223 GVDSSFVRL already exists\n",
      "224 SPSQDFMRF already exists\n",
      "225 PDYLQLARA already exists\n",
      "226 VYGMLFKFL already exists\n",
      "227 GFGSLFKFL already exists\n",
      "228 TPQQDFMRF already exists\n",
      "229 KPEEDWGHK already exists\n",
      "230 QAKSQGGSN already exists\n",
      "231 CYIQSCPIG already exists\n",
      "232 GPDSAFLRL already exists\n",
      "233 GDCPWKPWC already exists\n",
      "234 CYINNCPLG already exists\n",
      "235 TPTHDFMRF already exists\n",
      "236 RPPGFTPFR already exists\n",
      "237 RPPGFTPFR already exists\n",
      "238 ARSDNFVRL already exists\n",
      "239 CYISNCPIG already exists\n",
      "240 NYDKNFLRF already exists\n",
      "241 GRAENFLRL already exists\n",
      "242 QQWAVGHFM already exists\n",
      "243 QQWAVGHFM already exists\n",
      "244 CIIRNCPRG already exists\n",
      "245 LPEQDFMRF already exists\n",
      "246 ADYLRLARA already exists\n",
      "247 DGGRNFLRF already exists\n",
      "248 TPSQDFMRF already exists\n",
      "249 APPGFTPFR already exists\n",
      "250 GRADNFLRL already exists\n",
      "251 MLHCKGNNL already exists\n",
      "252 ASGQDFMRF already exists\n",
      "253 AGLLVYPRL already exists\n",
      "254 GPPLLPPLP already exists\n",
      "255 GYNRSFLRF already exists\n",
      "256 FDDYGHMRF already exists\n",
      "257 DPHHDFMRF already exists\n",
      "258 SVQDNFIRF already exists\n",
      "259 ASNQDFMRF already exists\n",
      "260 HTAGFIPRL already exists\n",
      "261 CYINNCPVG already exists\n",
      "262 DSDSAFLIG already exists\n",
      "263 QVNFSPGWG already exists\n",
      "264 YAIVARPRF already exists\n",
      "265 GPDSSFLRL already exists\n",
      "266 GLGPRPLRF already exists\n",
      "267 CYFRNCPIG already exists\n",
      "268 APQPYAFGL already exists\n",
      "269 ADYLQLARA already exists\n",
      "270 LPDSSFLRL already exists\n",
      "271 KFCPEGKCV already exists\n",
      "272 YAIAGRPRF already exists\n",
      "273 CYIQNCPVG already exists\n",
      "274 GPDSTFLRL already exists\n",
      "275 KPEEDWGHR already exists\n",
      "276 QKKDKKDRF already exists\n",
      "277 MFHDLPGVK already exists\n",
      "278 QGLIAFPRV already exists\n",
      "279 SDYLQLART already exists\n",
      "280 QLTFTSSWG already exists\n",
      "281 SPTQDFMRF already exists\n",
      "282 TPGQDFMRF already exists\n",
      "283 YSQVSRPRF already exists\n",
      "284 KPNQDFMRF already exists\n",
      "285 AGLFAQPRL already exists\n",
      "286 ARTDNFVRL already exists\n",
      "287 GFGMLFKFL already exists\n",
      "288 CLIQDCPEG already exists\n",
      "289 GPESAFLRL already exists\n",
      "290 AGQDNFMRF already exists\n",
      "291 YSLRARPRF already exists\n",
      "292 AGQDGFMRF already exists\n",
      "293 RPPGWSPFR already exists\n",
      "294 QPSQDFMRF already exists\n",
      "295 CLITNCPRG already exists\n",
      "296 APSGFMGMR already exists\n",
      "297 ATGQYAFGL already exists\n",
      "298 GPSGFLGMR already exists\n",
      "299 SDYLQLARG already exists\n",
      "300 APTAFYGVR already exists\n",
      "301 QEYTGWMDF already exists\n",
      "302 DSDSAHLIG already exists\n",
      "303 QKKDKKDKF already exists\n",
      "304 CYFNNCPVG already exists\n",
      "305 GPSQDFMRF already exists\n",
      "306 TPNRDFMRF already exists\n",
      "307 GFGALFKFL already exists\n",
      "308 AQPSMRLRF already exists\n",
      "309 SGPGFMGVR already exists\n",
      "310 QGLISFPRV already exists\n",
      "311 PALIPFPRV already exists\n",
      "312 APASGFFGMR already exists\n",
      "313 APAMGFQGVR already exists\n",
      "314 QVTFSRDWSP already exists\n",
      "315 APPGFTPFRS already exists\n",
      "316 QFRPSYQIPP already exists\n",
      "317 APSMGFQGMR already exists\n",
      "318 QSVPTFTPRL already exists\n",
      "319 APVMGFQGMR already exists\n",
      "320 APSSGFFGTR already exists\n",
      "321 TPASGFFGMR already exists\n",
      "322 SPASGFFGMR already exists\n",
      "323 GYGDRNFLRF already exists\n",
      "324 LMYYTLPRPV already exists\n",
      "325 QNECPWKPWC already exists\n",
      "326 GPSMGFHGMR already exists\n",
      "327 DRTPALRLRF already exists\n",
      "328 QHWSHGLSPG already exists\n",
      "329 QQDYTGWMDF already exists\n",
      "330 HKLDSFIGLM already exists\n",
      "331 APAAGFFGMR already exists\n",
      "332 AGEPKLDAGV already exists\n",
      "333 CEGHSHDHGA already exists\n",
      "334 VPPGFTPFRQ already exists\n",
      "335 QQDYTGWFDF already exists\n",
      "336 QLWPRPQIPP already exists\n",
      "337 GPSSGFFGMR already exists\n",
      "338 PSPPGFSPFR already exists\n",
      "339 QVNFTPNWGT already exists\n",
      "340 APLMGFQGVR already exists\n",
      "341 QHWSLCHAPG already exists\n",
      "342 VPASGFFGMR already exists\n",
      "343 LSPTQDFMRF already exists\n",
      "344 QNWPSPKVPP already exists\n",
      "345 LTPETASFPR already exists\n",
      "346 APSLGFHGVR already exists\n",
      "347 SPPSQDFMRF already exists\n",
      "348 TSGLIAFPRL already exists\n",
      "349 APVPGLSPFR already exists\n",
      "350 QHWSYGWLPG already exists\n",
      "351 KPEEDWDRTD already exists\n",
      "352 NGAPQPFVRF already exists\n",
      "353 EEGGRPPPPI already exists\n",
      "354 QKKDRFLGLM already exists\n",
      "355 GPSSGFFGTR already exists\n",
      "356 QHWSDYFKPG already exists\n",
      "357 EAPPGFSPFR already exists\n",
      "358 QDVDHVFLRF already exists\n",
      "359 TDVDHVFLRF already exists\n",
      "360 APLSGFYGVR already exists\n",
      "361 AKFDKFYGLM already exists\n",
      "362 KPEEDWGRES already exists\n",
      "363 QNWPHPPMPP already exists\n",
      "364 QSDDYGHMRF already exists\n",
      "365 QNPNRFIGLM already exists\n",
      "366 DSDSAQNLIG already exists\n",
      "367 SAQGQDFMRF already exists\n",
      "368 QHWSYGLQPG already exists\n",
      "369 QKKDRFLGLF already exists\n",
      "370 YGEPKLDAGV already exists\n",
      "371 MQWDEAIHGS already exists\n",
      "372 AAASDNFMRF already exists\n",
      "373 SAPGQDFMRF already exists\n",
      "374 GPNPGFSPFR already exists\n",
      "375 QLTFTPGWGY already exists\n",
      "376 NPASGFFGMR already exists\n",
      "377 SAPSQDFMRF already exists\n",
      "378 APTDMYSFGL already exists\n",
      "379 PPGFTPFRIY already exists\n",
      "380 QHWSHGWYPG already exists\n",
      "381 AGGADNFMRF already exists\n",
      "382 HKINSFVGLM already exists\n",
      "383 HNPASFIGLM already exists\n",
      "384 APSMGFMGMR already exists\n",
      "385 QDVVHSFLRF already exists\n",
      "386 DMHDFFVGLM already exists\n",
      "387 AAGQDNFMRF already exists\n",
      "388 QLWPRPHIPP already exists\n",
      "389 QWGQHPNIPP already exists\n",
      "390 QHWSHGWLPG already exists\n",
      "391 ALAGDHFFRF already exists\n",
      "392 DGCCIAKQCC already exists\n",
      "393 PDVDHVFLRF already exists\n",
      "394 QRWPSPKVPP already exists\n",
      "395 QGWPGPKVPP already exists\n",
      "396 YKSDSFYGLM already exists\n",
      "397 LAAGKVEDSD already exists\n",
      "398 QNWPRPQIPP already exists\n",
      "399 QFNEYGHMRF already exists\n",
      "400 QLTFSSGWGN already exists\n",
      "401 FFVPPAFFPP already exists\n",
      "402 AYSNLNYLRF already exists\n",
      "403 TPSDGFMGMR already exists\n",
      "404 QHWSHDWKPG already exists\n",
      "405 QVNFSPGWGT already exists\n",
      "406 ESECPWHPWC already exists\n",
      "407 QDLDHVFMRF already exists\n",
      "408 GPPYQPLVPR already exists\n",
      "409 AAAGDNFMRF already exists\n",
      "410 QLTFTPNWGT already exists\n",
      "411 MVDKFNNSDC already exists\n",
      "412 QKKDKKDRFY already exists\n",
      "413 APQAGFYGVR already exists\n",
      "414 QHYSLEWKPG already exists\n",
      "415 SSSGLISMPRV already exists\n",
      "416 QQDYTGAHFDF already exists\n",
      "417 APPGFTPFRID already exists\n",
      "418 GSSGLISMTRV already exists\n",
      "419 QNGPRPIGIPP already exists\n",
      "420 MSHDLDPTGTY already exists\n",
      "421 DEGGTQYTPRL already exists\n",
      "422 ESAGLIPFPRV already exists\n",
      "423 GHGGASNYVRL already exists\n",
      "424 GTSGLISFPRT already exists\n",
      "425 GSSGLISVPRV already exists\n",
      "426 GNWCCSARVCC already exists\n",
      "427 SVNTKNDFMRF already exists\n",
      "428 RPPGFSPFRVD already exists\n",
      "429 APSSMGFMGMR already exists\n",
      "430 CCHSSWCKHLC already exists\n",
      "431 QPDPNAFYGLM already exists\n",
      "432 QPSKDAFIGLM already exists\n",
      "433 GASGLIPFPRL already exists\n",
      "434 PAPDSSFLRDP already exists\n",
      "435 MSVSCWEFNAG already exists\n",
      "436 EQFDDYGHMRF already exists\n",
      "437 QQDYTGSHMDF already exists\n",
      "438 QQDYTGAHMDF already exists\n",
      "439 VPPGFTPFRVD already exists\n",
      "440 QGPSPRHPIPP already exists\n",
      "441 DCLPCGHDVCC already exists\n",
      "442 QPHPNEFVGLM already exists\n",
      "443 QGRPLGPPIPP already exists\n",
      "444 KPNPERFYGLM already exists\n",
      "445 RCCGYKFCHIC already exists\n",
      "446 SPATMGFAGVR already exists\n",
      "447 GSSGLIPFPRV already exists\n",
      "448 APGDRIYVHPF already exists\n",
      "449 RCCGYKMCHPC already exists\n",
      "450 PAPESNFVRDP already exists\n",
      "451 MGQEQGIPWIL already exists\n",
      "452 QQWPPGHHIPP already exists\n",
      "453 GRGGASNYVRL already exists\n",
      "454 QWPRPTPQIPP already exists\n",
      "455 QGRPPGPPIPP already exists\n",
      "       peptide  mutations  similarity\n",
      "0  CPSPDRFYGLM          1    0.909091\n",
      "1  GPSPDRFYGLM          1    0.909091\n",
      "2  RPSPDRFYGLM          1    0.909091\n",
      "3  LPSPDRFYGLM          1    0.909091\n",
      "4  KCSPDRFYGLM          1    0.909091\n",
      "5  KRSPDRFYGLM          1    0.909091\n",
      "6  KKSPDRFYGLM          1    0.909091\n",
      "7  KLSPDRFYGLM          1    0.909091\n",
      "8  KPCPDRFYGLM          1    0.909091\n",
      "9  KPGPDRFYGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CRGASSNYVRL          1    0.909091\n",
      "1  GRGASSNYVRL          1    0.909091\n",
      "2  RRGASSNYVRL          1    0.909091\n",
      "3  LRGASSNYVRL          1    0.909091\n",
      "4  GCGASSNYVRL          1    0.909091\n",
      "5  GRGASSNYVRL          1    0.909091\n",
      "6  GKGASSNYVRL          1    0.909091\n",
      "7  GLGASSNYVRL          1    0.909091\n",
      "8  GRCASSNYVRL          1    0.909091\n",
      "9  GRGASSNYVRL          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAPESGFIRDP          1    0.909091\n",
      "1  GAPESGFIRDP          1    0.909091\n",
      "2  RAPESGFIRDP          1    0.909091\n",
      "3  LAPESGFIRDP          1    0.909091\n",
      "4  PCPESGFIRDP          1    0.909091\n",
      "5  PRPESGFIRDP          1    0.909091\n",
      "6  PKPESGFIRDP          1    0.909091\n",
      "7  PLPESGFIRDP          1    0.909091\n",
      "8  PACESGFIRDP          1    0.909091\n",
      "9  PAGESGFIRDP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLIPMPRV          1    0.909091\n",
      "1  GSSGLIPMPRV          1    0.909091\n",
      "2  RSSGLIPMPRV          1    0.909091\n",
      "3  LSSGLIPMPRV          1    0.909091\n",
      "4  GCSGLIPMPRV          1    0.909091\n",
      "5  GRSGLIPMPRV          1    0.909091\n",
      "6  GKSGLIPMPRV          1    0.909091\n",
      "7  GLSGLIPMPRV          1    0.909091\n",
      "8  GSCGLIPMPRV          1    0.909091\n",
      "9  GSGGLIPMPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSTGLISFGRT          1    0.909091\n",
      "1  GSTGLISFGRT          1    0.909091\n",
      "2  RSTGLISFGRT          1    0.909091\n",
      "3  LSTGLISFGRT          1    0.909091\n",
      "4  GCTGLISFGRT          1    0.909091\n",
      "5  GRTGLISFGRT          1    0.909091\n",
      "6  GKTGLISFGRT          1    0.909091\n",
      "7  GLTGLISFGRT          1    0.909091\n",
      "8  GSCGLISFGRT          1    0.909091\n",
      "9  GSGGLISFGRT          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CADPKTFYGLM          1    0.909091\n",
      "1  GADPKTFYGLM          1    0.909091\n",
      "2  RADPKTFYGLM          1    0.909091\n",
      "3  LADPKTFYGLM          1    0.909091\n",
      "4  QCDPKTFYGLM          1    0.909091\n",
      "5  QRDPKTFYGLM          1    0.909091\n",
      "6  QKDPKTFYGLM          1    0.909091\n",
      "7  QLDPKTFYGLM          1    0.909091\n",
      "8  QACPKTFYGLM          1    0.909091\n",
      "9  QAGPKTFYGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGMISFPRT          1    0.909091\n",
      "1  GSSGMISFPRT          1    0.909091\n",
      "2  RSSGMISFPRT          1    0.909091\n",
      "3  LSSGMISFPRT          1    0.909091\n",
      "4  GCSGMISFPRT          1    0.909091\n",
      "5  GRSGMISFPRT          1    0.909091\n",
      "6  GKSGMISFPRT          1    0.909091\n",
      "7  GLSGMISFPRT          1    0.909091\n",
      "8  GSCGMISFPRT          1    0.909091\n",
      "9  GSGGMISFPRT          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAAGLLPFPRL          1    0.909091\n",
      "1  GAAGLLPFPRL          1    0.909091\n",
      "2  RAAGLLPFPRL          1    0.909091\n",
      "3  LAAGLLPFPRL          1    0.909091\n",
      "4  ECAGLLPFPRL          1    0.909091\n",
      "5  ERAGLLPFPRL          1    0.909091\n",
      "6  EKAGLLPFPRL          1    0.909091\n",
      "7  ELAGLLPFPRL          1    0.909091\n",
      "8  EACGLLPFPRL          1    0.909091\n",
      "9  EAGGLLPFPRL          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLIPMGRV          1    0.909091\n",
      "1  GSSGLIPMGRV          1    0.909091\n",
      "2  RSSGLIPMGRV          1    0.909091\n",
      "3  LSSGLIPMGRV          1    0.909091\n",
      "4  GCSGLIPMGRV          1    0.909091\n",
      "5  GRSGLIPMGRV          1    0.909091\n",
      "6  GKSGLIPMGRV          1    0.909091\n",
      "7  GLSGLIPMGRV          1    0.909091\n",
      "8  GSCGLIPMGRV          1    0.909091\n",
      "9  GSGGLIPMGRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CASDSGFLRDP          1    0.909091\n",
      "1  GASDSGFLRDP          1    0.909091\n",
      "2  RASDSGFLRDP          1    0.909091\n",
      "3  LASDSGFLRDP          1    0.909091\n",
      "4  PCSDSGFLRDP          1    0.909091\n",
      "5  PRSDSGFLRDP          1    0.909091\n",
      "6  PKSDSGFLRDP          1    0.909091\n",
      "7  PLSDSGFLRDP          1    0.909091\n",
      "8  PACDSGFLRDP          1    0.909091\n",
      "9  PAGDSGFLRDP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGRHPPIPPAP          1    0.909091\n",
      "1  GGRHPPIPPAP          1    0.909091\n",
      "2  RGRHPPIPPAP          1    0.909091\n",
      "3  LGRHPPIPPAP          1    0.909091\n",
      "4  QCRHPPIPPAP          1    0.909091\n",
      "5  QRRHPPIPPAP          1    0.909091\n",
      "6  QKRHPPIPPAP          1    0.909091\n",
      "7  QLRHPPIPPAP          1    0.909091\n",
      "8  QGCHPPIPPAP          1    0.909091\n",
      "9  QGGHPPIPPAP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CCCGYKFCYIC          1    0.909091\n",
      "1  GCCGYKFCYIC          1    0.909091\n",
      "2  RCCGYKFCYIC          1    0.909091\n",
      "3  LCCGYKFCYIC          1    0.909091\n",
      "4  RCCGYKFCYIC          1    0.909091\n",
      "5  RRCGYKFCYIC          1    0.909091\n",
      "6  RKCGYKFCYIC          1    0.909091\n",
      "7  RLCGYKFCYIC          1    0.909091\n",
      "8  RCCGYKFCYIC          1    0.909091\n",
      "9  RCGGYKFCYIC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CASGLIAFPRV          1    0.909091\n",
      "1  GASGLIAFPRV          1    0.909091\n",
      "2  RASGLIAFPRV          1    0.909091\n",
      "3  LASGLIAFPRV          1    0.909091\n",
      "4  GCSGLIAFPRV          1    0.909091\n",
      "5  GRSGLIAFPRV          1    0.909091\n",
      "6  GKSGLIAFPRV          1    0.909091\n",
      "7  GLSGLIAFPRV          1    0.909091\n",
      "8  GACGLIAFPRV          1    0.909091\n",
      "9  GAGGLIAFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAPWPDTISPP          1    0.909091\n",
      "1  GAPWPDTISPP          1    0.909091\n",
      "2  RAPWPDTISPP          1    0.909091\n",
      "3  LAPWPDTISPP          1    0.909091\n",
      "4  QCPWPDTISPP          1    0.909091\n",
      "5  QRPWPDTISPP          1    0.909091\n",
      "6  QKPWPDTISPP          1    0.909091\n",
      "7  QLPWPDTISPP          1    0.909091\n",
      "8  QACWPDTISPP          1    0.909091\n",
      "9  QAGWPDTISPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CCCGYKLCHPC          1    0.909091\n",
      "1  GCCGYKLCHPC          1    0.909091\n",
      "2  RCCGYKLCHPC          1    0.909091\n",
      "3  LCCGYKLCHPC          1    0.909091\n",
      "4  VCCGYKLCHPC          1    0.909091\n",
      "5  VRCGYKLCHPC          1    0.909091\n",
      "6  VKCGYKLCHPC          1    0.909091\n",
      "7  VLCGYKLCHPC          1    0.909091\n",
      "8  VCCGYKLCHPC          1    0.909091\n",
      "9  VCGGYKLCHPC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CTRPPGFTPFR          1    0.909091\n",
      "1  GTRPPGFTPFR          1    0.909091\n",
      "2  RTRPPGFTPFR          1    0.909091\n",
      "3  LTRPPGFTPFR          1    0.909091\n",
      "4  DCRPPGFTPFR          1    0.909091\n",
      "5  DRRPPGFTPFR          1    0.909091\n",
      "6  DKRPPGFTPFR          1    0.909091\n",
      "7  DLRPPGFTPFR          1    0.909091\n",
      "8  DTCPPGFTPFR          1    0.909091\n",
      "9  DTGPPGFTPFR          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGGPPRPQIPP          1    0.909091\n",
      "1  GGGPPRPQIPP          1    0.909091\n",
      "2  RGGPPRPQIPP          1    0.909091\n",
      "3  LGGPPRPQIPP          1    0.909091\n",
      "4  QCGPPRPQIPP          1    0.909091\n",
      "5  QRGPPRPQIPP          1    0.909091\n",
      "6  QKGPPRPQIPP          1    0.909091\n",
      "7  QLGPPRPQIPP          1    0.909091\n",
      "8  QGCPPRPQIPP          1    0.909091\n",
      "9  QGGPPRPQIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPRPGQFFGLM          1    0.909091\n",
      "1  GPRPGQFFGLM          1    0.909091\n",
      "2  RPRPGQFFGLM          1    0.909091\n",
      "3  LPRPGQFFGLM          1    0.909091\n",
      "4  KCRPGQFFGLM          1    0.909091\n",
      "5  KRRPGQFFGLM          1    0.909091\n",
      "6  KKRPGQFFGLM          1    0.909091\n",
      "7  KLRPGQFFGLM          1    0.909091\n",
      "8  KPCPGQFFGLM          1    0.909091\n",
      "9  KPGPGQFFGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPPGFTPFRIA          1    0.909091\n",
      "1  GPPGFTPFRIA          1    0.909091\n",
      "2  RPPGFTPFRIA          1    0.909091\n",
      "3  LPPGFTPFRIA          1    0.909091\n",
      "4  ACPGFTPFRIA          1    0.909091\n",
      "5  ARPGFTPFRIA          1    0.909091\n",
      "6  AKPGFTPFRIA          1    0.909091\n",
      "7  ALPGFTPFRIA          1    0.909091\n",
      "8  APCGFTPFRIA          1    0.909091\n",
      "9  APGGFTPFRIA          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLISFPRT          1    0.909091\n",
      "1  GSSGLISFPRT          1    0.909091\n",
      "2  RSSGLISFPRT          1    0.909091\n",
      "3  LSSGLISFPRT          1    0.909091\n",
      "4  GCSGLISFPRT          1    0.909091\n",
      "5  GRSGLISFPRT          1    0.909091\n",
      "6  GKSGLISFPRT          1    0.909091\n",
      "7  GLSGLISFPRT          1    0.909091\n",
      "8  GSCGLISFPRT          1    0.909091\n",
      "9  GSGGLISFPRT          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CQDYGTGWMDF          1    0.909091\n",
      "1  GQDYGTGWMDF          1    0.909091\n",
      "2  RQDYGTGWMDF          1    0.909091\n",
      "3  LQDYGTGWMDF          1    0.909091\n",
      "4  QCDYGTGWMDF          1    0.909091\n",
      "5  QRDYGTGWMDF          1    0.909091\n",
      "6  QKDYGTGWMDF          1    0.909091\n",
      "7  QLDYGTGWMDF          1    0.909091\n",
      "8  QQCYGTGWMDF          1    0.909091\n",
      "9  QQGYGTGWMDF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CNRHPPIPPAP          1    0.909091\n",
      "1  GNRHPPIPPAP          1    0.909091\n",
      "2  RNRHPPIPPAP          1    0.909091\n",
      "3  LNRHPPIPPAP          1    0.909091\n",
      "4  QCRHPPIPPAP          1    0.909091\n",
      "5  QRRHPPIPPAP          1    0.909091\n",
      "6  QKRHPPIPPAP          1    0.909091\n",
      "7  QLRHPPIPPAP          1    0.909091\n",
      "8  QNCHPPIPPAP          1    0.909091\n",
      "9  QNGHPPIPPAP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGGWPRNPIPP          1    0.909091\n",
      "1  GGGWPRNPIPP          1    0.909091\n",
      "2  RGGWPRNPIPP          1    0.909091\n",
      "3  LGGWPRNPIPP          1    0.909091\n",
      "4  QCGWPRNPIPP          1    0.909091\n",
      "5  QRGWPRNPIPP          1    0.909091\n",
      "6  QKGWPRNPIPP          1    0.909091\n",
      "7  QLGWPRNPIPP          1    0.909091\n",
      "8  QGCWPRNPIPP          1    0.909091\n",
      "9  QGGWPRNPIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGIIPFPRV          1    0.909091\n",
      "1  GSSGIIPFPRV          1    0.909091\n",
      "2  RSSGIIPFPRV          1    0.909091\n",
      "3  LSSGIIPFPRV          1    0.909091\n",
      "4  GCSGIIPFPRV          1    0.909091\n",
      "5  GRSGIIPFPRV          1    0.909091\n",
      "6  GKSGIIPFPRV          1    0.909091\n",
      "7  GLSGIIPFPRV          1    0.909091\n",
      "8  GSCGIIPFPRV          1    0.909091\n",
      "9  GSGGIIPFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPPGFTPFRSK          1    0.909091\n",
      "1  GPPGFTPFRSK          1    0.909091\n",
      "2  RPPGFTPFRSK          1    0.909091\n",
      "3  LPPGFTPFRSK          1    0.909091\n",
      "4  ACPGFTPFRSK          1    0.909091\n",
      "5  ARPGFTPFRSK          1    0.909091\n",
      "6  AKPGFTPFRSK          1    0.909091\n",
      "7  ALPGFTPFRSK          1    0.909091\n",
      "8  APCGFTPFRSK          1    0.909091\n",
      "9  APGGFTPFRSK          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLIAFPRL          1    0.909091\n",
      "1  GSSGLIAFPRL          1    0.909091\n",
      "2  RSSGLIAFPRL          1    0.909091\n",
      "3  LSSGLIAFPRL          1    0.909091\n",
      "4  GCSGLIAFPRL          1    0.909091\n",
      "5  GRSGLIAFPRL          1    0.909091\n",
      "6  GKSGLIAFPRL          1    0.909091\n",
      "7  GLSGLIAFPRL          1    0.909091\n",
      "8  GSCGLIAFPRL          1    0.909091\n",
      "9  GSGGLIAFPRL          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGQEQDTPWIL          1    0.909091\n",
      "1  GGQEQDTPWIL          1    0.909091\n",
      "2  RGQEQDTPWIL          1    0.909091\n",
      "3  LGQEQDTPWIL          1    0.909091\n",
      "4  MCQEQDTPWIL          1    0.909091\n",
      "5  MRQEQDTPWIL          1    0.909091\n",
      "6  MKQEQDTPWIL          1    0.909091\n",
      "7  MLQEQDTPWIL          1    0.909091\n",
      "8  MGCEQDTPWIL          1    0.909091\n",
      "9  MGGEQDTPWIL          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPPGFTPFRIY          1    0.909091\n",
      "1  GPPGFTPFRIY          1    0.909091\n",
      "2  RPPGFTPFRIY          1    0.909091\n",
      "3  LPPGFTPFRIY          1    0.909091\n",
      "4  ACPGFTPFRIY          1    0.909091\n",
      "5  ARPGFTPFRIY          1    0.909091\n",
      "6  AKPGFTPFRIY          1    0.909091\n",
      "7  ALPGFTPFRIY          1    0.909091\n",
      "8  APCGFTPFRIY          1    0.909091\n",
      "9  APGGFTPFRIY          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLIAMPRV          1    0.909091\n",
      "1  GSSGLIAMPRV          1    0.909091\n",
      "2  RSSGLIAMPRV          1    0.909091\n",
      "3  LSSGLIAMPRV          1    0.909091\n",
      "4  GCSGLIAMPRV          1    0.909091\n",
      "5  GRSGLIAMPRV          1    0.909091\n",
      "6  GKSGLIAMPRV          1    0.909091\n",
      "7  GLSGLIAMPRV          1    0.909091\n",
      "8  GSCGLIAMPRV          1    0.909091\n",
      "9  GSGGLIAMPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CQVGLIPFPRV          1    0.909091\n",
      "1  GQVGLIPFPRV          1    0.909091\n",
      "2  RQVGLIPFPRV          1    0.909091\n",
      "3  LQVGLIPFPRV          1    0.909091\n",
      "4  PCVGLIPFPRV          1    0.909091\n",
      "5  PRVGLIPFPRV          1    0.909091\n",
      "6  PKVGLIPFPRV          1    0.909091\n",
      "7  PLVGLIPFPRV          1    0.909091\n",
      "8  PQCGLIPFPRV          1    0.909091\n",
      "9  PQGGLIPFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CASGLISFPRV          1    0.909091\n",
      "1  GASGLISFPRV          1    0.909091\n",
      "2  RASGLISFPRV          1    0.909091\n",
      "3  LASGLISFPRV          1    0.909091\n",
      "4  GCSGLISFPRV          1    0.909091\n",
      "5  GRSGLISFPRV          1    0.909091\n",
      "6  GKSGLISFPRV          1    0.909091\n",
      "7  GLSGLISFPRV          1    0.909091\n",
      "8  GACGLISFPRV          1    0.909091\n",
      "9  GAGGLISFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGGAGWPPIPP          1    0.909091\n",
      "1  GGGAGWPPIPP          1    0.909091\n",
      "2  RGGAGWPPIPP          1    0.909091\n",
      "3  LGGAGWPPIPP          1    0.909091\n",
      "4  QCGAGWPPIPP          1    0.909091\n",
      "5  QRGAGWPPIPP          1    0.909091\n",
      "6  QKGAGWPPIPP          1    0.909091\n",
      "7  QLGAGWPPIPP          1    0.909091\n",
      "8  QGCAGWPPIPP          1    0.909091\n",
      "9  QGGAGWPPIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSAPGNEAIPP          1    0.909091\n",
      "1  GSAPGNEAIPP          1    0.909091\n",
      "2  RSAPGNEAIPP          1    0.909091\n",
      "3  LSAPGNEAIPP          1    0.909091\n",
      "4  QCAPGNEAIPP          1    0.909091\n",
      "5  QRAPGNEAIPP          1    0.909091\n",
      "6  QKAPGNEAIPP          1    0.909091\n",
      "7  QLAPGNEAIPP          1    0.909091\n",
      "8  QSCPGNEAIPP          1    0.909091\n",
      "9  QSGPGNEAIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CANTKNDFMRF          1    0.909091\n",
      "1  GANTKNDFMRF          1    0.909091\n",
      "2  RANTKNDFMRF          1    0.909091\n",
      "3  LANTKNDFMRF          1    0.909091\n",
      "4  SCNTKNDFMRF          1    0.909091\n",
      "5  SRNTKNDFMRF          1    0.909091\n",
      "6  SKNTKNDFMRF          1    0.909091\n",
      "7  SLNTKNDFMRF          1    0.909091\n",
      "8  SACTKNDFMRF          1    0.909091\n",
      "9  SAGTKNDFMRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CQRSPSLRLRF          1    0.909091\n",
      "1  GQRSPSLRLRF          1    0.909091\n",
      "2  RQRSPSLRLRF          1    0.909091\n",
      "3  LQRSPSLRLRF          1    0.909091\n",
      "4  ACRSPSLRLRF          1    0.909091\n",
      "5  ARRSPSLRLRF          1    0.909091\n",
      "6  AKRSPSLRLRF          1    0.909091\n",
      "7  ALRSPSLRLRF          1    0.909091\n",
      "8  AQCSPSLRLRF          1    0.909091\n",
      "9  AQGSPSLRLRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CRGGSSNYVRL          1    0.909091\n",
      "1  GRGGSSNYVRL          1    0.909091\n",
      "2  RRGGSSNYVRL          1    0.909091\n",
      "3  LRGGSSNYVRL          1    0.909091\n",
      "4  GCGGSSNYVRL          1    0.909091\n",
      "5  GRGGSSNYVRL          1    0.909091\n",
      "6  GKGGSSNYVRL          1    0.909091\n",
      "7  GLGGSSNYVRL          1    0.909091\n",
      "8  GRCGSSNYVRL          1    0.909091\n",
      "9  GRGGSSNYVRL          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CQDYTGSHFDF          1    0.909091\n",
      "1  GQDYTGSHFDF          1    0.909091\n",
      "2  RQDYTGSHFDF          1    0.909091\n",
      "3  LQDYTGSHFDF          1    0.909091\n",
      "4  QCDYTGSHFDF          1    0.909091\n",
      "5  QRDYTGSHFDF          1    0.909091\n",
      "6  QKDYTGSHFDF          1    0.909091\n",
      "7  QLDYTGSHFDF          1    0.909091\n",
      "8  QQCYTGSHFDF          1    0.909091\n",
      "9  QQGYTGSHFDF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CCCPVIRYCCW          1    0.909091\n",
      "1  GCCPVIRYCCW          1    0.909091\n",
      "2  RCCPVIRYCCW          1    0.909091\n",
      "3  LCCPVIRYCCW          1    0.909091\n",
      "4  FCCPVIRYCCW          1    0.909091\n",
      "5  FRCPVIRYCCW          1    0.909091\n",
      "6  FKCPVIRYCCW          1    0.909091\n",
      "7  FLCPVIRYCCW          1    0.909091\n",
      "8  FCCPVIRYCCW          1    0.909091\n",
      "9  FCGPVIRYCCW          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPRPQQFFGLM          1    0.909091\n",
      "1  GPRPQQFFGLM          1    0.909091\n",
      "2  RPRPQQFFGLM          1    0.909091\n",
      "3  LPRPQQFFGLM          1    0.909091\n",
      "4  RCRPQQFFGLM          1    0.909091\n",
      "5  RRRPQQFFGLM          1    0.909091\n",
      "6  RKRPQQFFGLM          1    0.909091\n",
      "7  RLRPQQFFGLM          1    0.909091\n",
      "8  RPCPQQFFGLM          1    0.909091\n",
      "9  RPGPQQFFGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CCSCKRNFLCC          1    0.909091\n",
      "1  GCSCKRNFLCC          1    0.909091\n",
      "2  RCSCKRNFLCC          1    0.909091\n",
      "3  LCSCKRNFLCC          1    0.909091\n",
      "4  SCSCKRNFLCC          1    0.909091\n",
      "5  SRSCKRNFLCC          1    0.909091\n",
      "6  SKSCKRNFLCC          1    0.909091\n",
      "7  SLSCKRNFLCC          1    0.909091\n",
      "8  SCCCKRNFLCC          1    0.909091\n",
      "9  SCGCKRNFLCC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSTGLIPFGRP          1    0.909091\n",
      "1  GSTGLIPFGRP          1    0.909091\n",
      "2  RSTGLIPFGRP          1    0.909091\n",
      "3  LSTGLIPFGRP          1    0.909091\n",
      "4  GCTGLIPFGRP          1    0.909091\n",
      "5  GRTGLIPFGRP          1    0.909091\n",
      "6  GKTGLIPFGRP          1    0.909091\n",
      "7  GLTGLIPFGRP          1    0.909091\n",
      "8  GSCGLIPFGRP          1    0.909091\n",
      "9  GSGGLIPFGRP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGGAPWNPIPP          1    0.909091\n",
      "1  GGGAPWNPIPP          1    0.909091\n",
      "2  RGGAPWNPIPP          1    0.909091\n",
      "3  LGGAPWNPIPP          1    0.909091\n",
      "4  QCGAPWNPIPP          1    0.909091\n",
      "5  QRGAPWNPIPP          1    0.909091\n",
      "6  QKGAPWNPIPP          1    0.909091\n",
      "7  QLGAPWNPIPP          1    0.909091\n",
      "8  QGCAPWNPIPP          1    0.909091\n",
      "9  QGGAPWNPIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CADPNAFYGLM          1    0.909091\n",
      "1  GADPNAFYGLM          1    0.909091\n",
      "2  RADPNAFYGLM          1    0.909091\n",
      "3  LADPNAFYGLM          1    0.909091\n",
      "4  QCDPNAFYGLM          1    0.909091\n",
      "5  QRDPNAFYGLM          1    0.909091\n",
      "6  QKDPNAFYGLM          1    0.909091\n",
      "7  QLDPNAFYGLM          1    0.909091\n",
      "8  QACPNAFYGLM          1    0.909091\n",
      "9  QAGPNAFYGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAPETNYLRDP          1    0.909091\n",
      "1  GAPETNYLRDP          1    0.909091\n",
      "2  RAPETNYLRDP          1    0.909091\n",
      "3  LAPETNYLRDP          1    0.909091\n",
      "4  PCPETNYLRDP          1    0.909091\n",
      "5  PRPETNYLRDP          1    0.909091\n",
      "6  PKPETNYLRDP          1    0.909091\n",
      "7  PLPETNYLRDP          1    0.909091\n",
      "8  PACETNYLRDP          1    0.909091\n",
      "9  PAGETNYLRDP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLISMPRV          1    0.909091\n",
      "1  GSSGLISMPRV          1    0.909091\n",
      "2  RSSGLISMPRV          1    0.909091\n",
      "3  LSSGLISMPRV          1    0.909091\n",
      "4  GCSGLISMPRV          1    0.909091\n",
      "5  GRSGLISMPRV          1    0.909091\n",
      "6  GKSGLISMPRV          1    0.909091\n",
      "7  GLSGLISMPRV          1    0.909091\n",
      "8  GSCGLISMPRV          1    0.909091\n",
      "9  GSGGLISMPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAAGLISFPRV          1    0.909091\n",
      "1  GAAGLISFPRV          1    0.909091\n",
      "2  RAAGLISFPRV          1    0.909091\n",
      "3  LAAGLISFPRV          1    0.909091\n",
      "4  ECAGLISFPRV          1    0.909091\n",
      "5  ERAGLISFPRV          1    0.909091\n",
      "6  EKAGLISFPRV          1    0.909091\n",
      "7  ELAGLISFPRV          1    0.909091\n",
      "8  EACGLISFPRV          1    0.909091\n",
      "9  EAGGLISFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAAYLDPTGQY          1    0.909091\n",
      "1  GAAYLDPTGQY          1    0.909091\n",
      "2  RAAYLDPTGQY          1    0.909091\n",
      "3  LAAYLDPTGQY          1    0.909091\n",
      "4  MCAYLDPTGQY          1    0.909091\n",
      "5  MRAYLDPTGQY          1    0.909091\n",
      "6  MKAYLDPTGQY          1    0.909091\n",
      "7  MLAYLDPTGQY          1    0.909091\n",
      "8  MACYLDPTGQY          1    0.909091\n",
      "9  MAGYLDPTGQY          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPNPDEFFGLM          1    0.909091\n",
      "1  GPNPDEFFGLM          1    0.909091\n",
      "2  RPNPDEFFGLM          1    0.909091\n",
      "3  LPNPDEFFGLM          1    0.909091\n",
      "4  QCNPDEFFGLM          1    0.909091\n",
      "5  QRNPDEFFGLM          1    0.909091\n",
      "6  QKNPDEFFGLM          1    0.909091\n",
      "7  QLNPDEFFGLM          1    0.909091\n",
      "8  QPCPDEFFGLM          1    0.909091\n",
      "9  QPGPDEFFGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPHPDEFVGLM          1    0.909091\n",
      "1  GPHPDEFVGLM          1    0.909091\n",
      "2  RPHPDEFVGLM          1    0.909091\n",
      "3  LPHPDEFVGLM          1    0.909091\n",
      "4  QCHPDEFVGLM          1    0.909091\n",
      "5  QRHPDEFVGLM          1    0.909091\n",
      "6  QKHPDEFVGLM          1    0.909091\n",
      "7  QLHPDEFVGLM          1    0.909091\n",
      "8  QPCPDEFVGLM          1    0.909091\n",
      "9  QPGPDEFVGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSTGLIPFGRT          1    0.909091\n",
      "1  GSTGLIPFGRT          1    0.909091\n",
      "2  RSTGLIPFGRT          1    0.909091\n",
      "3  LSTGLIPFGRT          1    0.909091\n",
      "4  GCTGLIPFGRT          1    0.909091\n",
      "5  GRTGLIPFGRT          1    0.909091\n",
      "6  GKTGLIPFGRT          1    0.909091\n",
      "7  GLTGLIPFGRT          1    0.909091\n",
      "8  GSCGLIPFGRT          1    0.909091\n",
      "9  GSGGLIPFGRT          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CCCPFIRYCCW          1    0.909091\n",
      "1  GCCPFIRYCCW          1    0.909091\n",
      "2  RCCPFIRYCCW          1    0.909091\n",
      "3  LCCPFIRYCCW          1    0.909091\n",
      "4  FCCPFIRYCCW          1    0.909091\n",
      "5  FRCPFIRYCCW          1    0.909091\n",
      "6  FKCPFIRYCCW          1    0.909091\n",
      "7  FLCPFIRYCCW          1    0.909091\n",
      "8  FCCPFIRYCCW          1    0.909091\n",
      "9  FCGPFIRYCCW          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLISMPRV          1    0.909091\n",
      "1  GSSGLISMPRV          1    0.909091\n",
      "2  RSSGLISMPRV          1    0.909091\n",
      "3  LSSGLISMPRV          1    0.909091\n",
      "4  ACSGLISMPRV          1    0.909091\n",
      "5  ARSGLISMPRV          1    0.909091\n",
      "6  AKSGLISMPRV          1    0.909091\n",
      "7  ALSGLISMPRV          1    0.909091\n",
      "8  ASCGLISMPRV          1    0.909091\n",
      "9  ASGGLISMPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CASGLIPVMRN          1    0.909091\n",
      "1  GASGLIPVMRN          1    0.909091\n",
      "2  RASGLIPVMRN          1    0.909091\n",
      "3  LASGLIPVMRN          1    0.909091\n",
      "4  GCSGLIPVMRN          1    0.909091\n",
      "5  GRSGLIPVMRN          1    0.909091\n",
      "6  GKSGLIPVMRN          1    0.909091\n",
      "7  GLSGLIPVMRN          1    0.909091\n",
      "8  GACGLIPVMRN          1    0.909091\n",
      "9  GAGGLIPVMRN          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGRTPALRLRF          1    0.909091\n",
      "1  GGRTPALRLRF          1    0.909091\n",
      "2  RGRTPALRLRF          1    0.909091\n",
      "3  LGRTPALRLRF          1    0.909091\n",
      "4  DCRTPALRLRF          1    0.909091\n",
      "5  DRRTPALRLRF          1    0.909091\n",
      "6  DKRTPALRLRF          1    0.909091\n",
      "7  DLRTPALRLRF          1    0.909091\n",
      "8  DGCTPALRLRF          1    0.909091\n",
      "9  DGGTPALRLRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGMIPFPRV          1    0.909091\n",
      "1  GSSGMIPFPRV          1    0.909091\n",
      "2  RSSGMIPFPRV          1    0.909091\n",
      "3  LSSGMIPFPRV          1    0.909091\n",
      "4  GCSGMIPFPRV          1    0.909091\n",
      "5  GRSGMIPFPRV          1    0.909091\n",
      "6  GKSGMIPFPRV          1    0.909091\n",
      "7  GLSGMIPFPRV          1    0.909091\n",
      "8  GSCGMIPFPRV          1    0.909091\n",
      "9  GSGGMIPFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CWPDPSSDIPP          1    0.909091\n",
      "1  GWPDPSSDIPP          1    0.909091\n",
      "2  RWPDPSSDIPP          1    0.909091\n",
      "3  LWPDPSSDIPP          1    0.909091\n",
      "4  QCPDPSSDIPP          1    0.909091\n",
      "5  QRPDPSSDIPP          1    0.909091\n",
      "6  QKPDPSSDIPP          1    0.909091\n",
      "7  QLPDPSSDIPP          1    0.909091\n",
      "8  QWCDPSSDIPP          1    0.909091\n",
      "9  QWGDPSSDIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CTPQWATGHFM          1    0.909091\n",
      "1  GTPQWATGHFM          1    0.909091\n",
      "2  RTPQWATGHFM          1    0.909091\n",
      "3  LTPQWATGHFM          1    0.909091\n",
      "4  QCPQWATGHFM          1    0.909091\n",
      "5  QRPQWATGHFM          1    0.909091\n",
      "6  QKPQWATGHFM          1    0.909091\n",
      "7  QLPQWATGHFM          1    0.909091\n",
      "8  QTCQWATGHFM          1    0.909091\n",
      "9  QTGQWATGHFM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "513 QTPQWATGHFM already exists\n",
      "       peptide  mutations  similarity\n",
      "0  CPNPDEFVGLM          1    0.909091\n",
      "1  GPNPDEFVGLM          1    0.909091\n",
      "2  RPNPDEFVGLM          1    0.909091\n",
      "3  LPNPDEFVGLM          1    0.909091\n",
      "4  QCNPDEFVGLM          1    0.909091\n",
      "5  QRNPDEFVGLM          1    0.909091\n",
      "6  QKNPDEFVGLM          1    0.909091\n",
      "7  QLNPDEFVGLM          1    0.909091\n",
      "8  QPCPDEFVGLM          1    0.909091\n",
      "9  QPGPDEFVGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPPGGSKVILF          1    0.909091\n",
      "1  GPPGGSKVILF          1    0.909091\n",
      "2  RPPGGSKVILF          1    0.909091\n",
      "3  LPPGGSKVILF          1    0.909091\n",
      "4  QCPGGSKVILF          1    0.909091\n",
      "5  QRPGGSKVILF          1    0.909091\n",
      "6  QKPGGSKVILF          1    0.909091\n",
      "7  QLPGGSKVILF          1    0.909091\n",
      "8  QPCGGSKVILF          1    0.909091\n",
      "9  QPGGGSKVILF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CARPRHPKIPP          1    0.909091\n",
      "1  GARPRHPKIPP          1    0.909091\n",
      "2  RARPRHPKIPP          1    0.909091\n",
      "3  LARPRHPKIPP          1    0.909091\n",
      "4  QCRPRHPKIPP          1    0.909091\n",
      "5  QRRPRHPKIPP          1    0.909091\n",
      "6  QKRPRHPKIPP          1    0.909091\n",
      "7  QLRPRHPKIPP          1    0.909091\n",
      "8  QACPRHPKIPP          1    0.909091\n",
      "9  QAGPRHPKIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CRGGPSNYVRL          1    0.909091\n",
      "1  GRGGPSNYVRL          1    0.909091\n",
      "2  RRGGPSNYVRL          1    0.909091\n",
      "3  LRGGPSNYVRL          1    0.909091\n",
      "4  GCGGPSNYVRL          1    0.909091\n",
      "5  GRGGPSNYVRL          1    0.909091\n",
      "6  GKGGPSNYVRL          1    0.909091\n",
      "7  GLGGPSNYVRL          1    0.909091\n",
      "8  GRCGPSNYVRL          1    0.909091\n",
      "9  GRGGPSNYVRL          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CLNTKNDFMRF          1    0.909091\n",
      "1  GLNTKNDFMRF          1    0.909091\n",
      "2  RLNTKNDFMRF          1    0.909091\n",
      "3  LLNTKNDFMRF          1    0.909091\n",
      "4  SCNTKNDFMRF          1    0.909091\n",
      "5  SRNTKNDFMRF          1    0.909091\n",
      "6  SKNTKNDFMRF          1    0.909091\n",
      "7  SLNTKNDFMRF          1    0.909091\n",
      "8  SLCTKNDFMRF          1    0.909091\n",
      "9  SLGTKNDFMRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLISFPRN          1    0.909091\n",
      "1  GSSGLISFPRN          1    0.909091\n",
      "2  RSSGLISFPRN          1    0.909091\n",
      "3  LSSGLISFPRN          1    0.909091\n",
      "4  GCSGLISFPRN          1    0.909091\n",
      "5  GRSGLISFPRN          1    0.909091\n",
      "6  GKSGLISFPRN          1    0.909091\n",
      "7  GLSGLISFPRN          1    0.909091\n",
      "8  GSCGLISFPRN          1    0.909091\n",
      "9  GSGGLISFPRN          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPPGFTPFRQS          1    0.909091\n",
      "1  GPPGFTPFRQS          1    0.909091\n",
      "2  RPPGFTPFRQS          1    0.909091\n",
      "3  LPPGFTPFRQS          1    0.909091\n",
      "4  VCPGFTPFRQS          1    0.909091\n",
      "5  VRPGFTPFRQS          1    0.909091\n",
      "6  VKPGFTPFRQS          1    0.909091\n",
      "7  VLPGFTPFRQS          1    0.909091\n",
      "8  VPCGFTPFRQS          1    0.909091\n",
      "9  VPGGFTPFRQS          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPPPPGPPPNP          1    0.909091\n",
      "1  GPPPPGPPPNP          1    0.909091\n",
      "2  RPPPPGPPPNP          1    0.909091\n",
      "3  LPPPPGPPPNP          1    0.909091\n",
      "4  PCPPPGPPPNP          1    0.909091\n",
      "5  PRPPPGPPPNP          1    0.909091\n",
      "6  PKPPPGPPPNP          1    0.909091\n",
      "7  PLPPPGPPPNP          1    0.909091\n",
      "8  PPCPPGPPPNP          1    0.909091\n",
      "9  PPGPPGPPPNP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CCQPCGHNVCC          1    0.909091\n",
      "1  GCQPCGHNVCC          1    0.909091\n",
      "2  RCQPCGHNVCC          1    0.909091\n",
      "3  LCQPCGHNVCC          1    0.909091\n",
      "4  DCQPCGHNVCC          1    0.909091\n",
      "5  DRQPCGHNVCC          1    0.909091\n",
      "6  DKQPCGHNVCC          1    0.909091\n",
      "7  DLQPCGHNVCC          1    0.909091\n",
      "8  DCCPCGHNVCC          1    0.909091\n",
      "9  DCGPCGHNVCC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CCCVYKICYPC          1    0.909091\n",
      "1  GCCVYKICYPC          1    0.909091\n",
      "2  RCCVYKICYPC          1    0.909091\n",
      "3  LCCVYKICYPC          1    0.909091\n",
      "4  ACCVYKICYPC          1    0.909091\n",
      "5  ARCVYKICYPC          1    0.909091\n",
      "6  AKCVYKICYPC          1    0.909091\n",
      "7  ALCVYKICYPC          1    0.909091\n",
      "8  ACCVYKICYPC          1    0.909091\n",
      "9  ACGVYKICYPC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CEGGSPPPVVI          1    0.909091\n",
      "1  GEGGSPPPVVI          1    0.909091\n",
      "2  REGGSPPPVVI          1    0.909091\n",
      "3  LEGGSPPPVVI          1    0.909091\n",
      "4  ECGGSPPPVVI          1    0.909091\n",
      "5  ERGGSPPPVVI          1    0.909091\n",
      "6  EKGGSPPPVVI          1    0.909091\n",
      "7  ELGGSPPPVVI          1    0.909091\n",
      "8  EECGSPPPVVI          1    0.909091\n",
      "9  EEGGSPPPVVI          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAAGLLPFPRV          1    0.909091\n",
      "1  GAAGLLPFPRV          1    0.909091\n",
      "2  RAAGLLPFPRV          1    0.909091\n",
      "3  LAAGLLPFPRV          1    0.909091\n",
      "4  ECAGLLPFPRV          1    0.909091\n",
      "5  ERAGLLPFPRV          1    0.909091\n",
      "6  EKAGLLPFPRV          1    0.909091\n",
      "7  ELAGLLPFPRV          1    0.909091\n",
      "8  EACGLLPFPRV          1    0.909091\n",
      "9  EAGGLLPFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CNAHPSPKVPP          1    0.909091\n",
      "1  GNAHPSPKVPP          1    0.909091\n",
      "2  RNAHPSPKVPP          1    0.909091\n",
      "3  LNAHPSPKVPP          1    0.909091\n",
      "4  QCAHPSPKVPP          1    0.909091\n",
      "5  QRAHPSPKVPP          1    0.909091\n",
      "6  QKAHPSPKVPP          1    0.909091\n",
      "7  QLAHPSPKVPP          1    0.909091\n",
      "8  QNCHPSPKVPP          1    0.909091\n",
      "9  QNGHPSPKVPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLIPMGRT          1    0.909091\n",
      "1  GSSGLIPMGRT          1    0.909091\n",
      "2  RSSGLIPMGRT          1    0.909091\n",
      "3  LSSGLIPMGRT          1    0.909091\n",
      "4  GCSGLIPMGRT          1    0.909091\n",
      "5  GRSGLIPMGRT          1    0.909091\n",
      "6  GKSGLIPMGRT          1    0.909091\n",
      "7  GLSGLIPMGRT          1    0.909091\n",
      "8  GSCGLIPMGRT          1    0.909091\n",
      "9  GSGGLIPMGRT          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CADPNKFYGLM          1    0.909091\n",
      "1  GADPNKFYGLM          1    0.909091\n",
      "2  RADPNKFYGLM          1    0.909091\n",
      "3  LADPNKFYGLM          1    0.909091\n",
      "4  QCDPNKFYGLM          1    0.909091\n",
      "5  QRDPNKFYGLM          1    0.909091\n",
      "6  QKDPNKFYGLM          1    0.909091\n",
      "7  QLDPNKFYGLM          1    0.909091\n",
      "8  QACPNKFYGLM          1    0.909091\n",
      "9  QAGPNKFYGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAPESSFIRDP          1    0.909091\n",
      "1  GAPESSFIRDP          1    0.909091\n",
      "2  RAPESSFIRDP          1    0.909091\n",
      "3  LAPESSFIRDP          1    0.909091\n",
      "4  PCPESSFIRDP          1    0.909091\n",
      "5  PRPESSFIRDP          1    0.909091\n",
      "6  PKPESSFIRDP          1    0.909091\n",
      "7  PLPESSFIRDP          1    0.909091\n",
      "8  PACESSFIRDP          1    0.909091\n",
      "9  PAGESSFIRDP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CQFEDYGHMRF          1    0.909091\n",
      "1  GQFEDYGHMRF          1    0.909091\n",
      "2  RQFEDYGHMRF          1    0.909091\n",
      "3  LQFEDYGHMRF          1    0.909091\n",
      "4  ECFEDYGHMRF          1    0.909091\n",
      "5  ERFEDYGHMRF          1    0.909091\n",
      "6  EKFEDYGHMRF          1    0.909091\n",
      "7  ELFEDYGHMRF          1    0.909091\n",
      "8  EQCEDYGHMRF          1    0.909091\n",
      "9  EQGEDYGHMRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CTCIPIPLVMC          1    0.909091\n",
      "1  GTCIPIPLVMC          1    0.909091\n",
      "2  RTCIPIPLVMC          1    0.909091\n",
      "3  LTCIPIPLVMC          1    0.909091\n",
      "4  RCCIPIPLVMC          1    0.909091\n",
      "5  RRCIPIPLVMC          1    0.909091\n",
      "6  RKCIPIPLVMC          1    0.909091\n",
      "7  RLCIPIPLVMC          1    0.909091\n",
      "8  RTCIPIPLVMC          1    0.909091\n",
      "9  RTGIPIPLVMC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPNPNEFFGLM          1    0.909091\n",
      "1  GPNPNEFFGLM          1    0.909091\n",
      "2  RPNPNEFFGLM          1    0.909091\n",
      "3  LPNPNEFFGLM          1    0.909091\n",
      "4  QCNPNEFFGLM          1    0.909091\n",
      "5  QRNPNEFFGLM          1    0.909091\n",
      "6  QKNPNEFFGLM          1    0.909091\n",
      "7  QLNPNEFFGLM          1    0.909091\n",
      "8  QPCPNEFFGLM          1    0.909091\n",
      "9  QPGPNEFFGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CQDYGTGWFDF          1    0.909091\n",
      "1  GQDYGTGWFDF          1    0.909091\n",
      "2  RQDYGTGWFDF          1    0.909091\n",
      "3  LQDYGTGWFDF          1    0.909091\n",
      "4  QCDYGTGWFDF          1    0.909091\n",
      "5  QRDYGTGWFDF          1    0.909091\n",
      "6  QKDYGTGWFDF          1    0.909091\n",
      "7  QLDYGTGWFDF          1    0.909091\n",
      "8  QQCYGTGWFDF          1    0.909091\n",
      "9  QQGYGTGWFDF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAAGLLAFPRV          1    0.909091\n",
      "1  GAAGLLAFPRV          1    0.909091\n",
      "2  RAAGLLAFPRV          1    0.909091\n",
      "3  LAAGLLAFPRV          1    0.909091\n",
      "4  ECAGLLAFPRV          1    0.909091\n",
      "5  ERAGLLAFPRV          1    0.909091\n",
      "6  EKAGLLAFPRV          1    0.909091\n",
      "7  ELAGLLAFPRV          1    0.909091\n",
      "8  EACGLLAFPRV          1    0.909091\n",
      "9  EAGGLLAFPRV          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPACVGFQGMR          1    0.909091\n",
      "1  GPACVGFQGMR          1    0.909091\n",
      "2  RPACVGFQGMR          1    0.909091\n",
      "3  LPACVGFQGMR          1    0.909091\n",
      "4  ACACVGFQGMR          1    0.909091\n",
      "5  ARACVGFQGMR          1    0.909091\n",
      "6  AKACVGFQGMR          1    0.909091\n",
      "7  ALACVGFQGMR          1    0.909091\n",
      "8  APCCVGFQGMR          1    0.909091\n",
      "9  APGCVGFQGMR          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGRPPRPHIPP          1    0.909091\n",
      "1  GGRPPRPHIPP          1    0.909091\n",
      "2  RGRPPRPHIPP          1    0.909091\n",
      "3  LGRPPRPHIPP          1    0.909091\n",
      "4  QCRPPRPHIPP          1    0.909091\n",
      "5  QRRPPRPHIPP          1    0.909091\n",
      "6  QKRPPRPHIPP          1    0.909091\n",
      "7  QLRPPRPHIPP          1    0.909091\n",
      "8  QGCPPRPHIPP          1    0.909091\n",
      "9  QGGPPRPHIPP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPNPERFYAPM          1    0.909091\n",
      "1  GPNPERFYAPM          1    0.909091\n",
      "2  RPNPERFYAPM          1    0.909091\n",
      "3  LPNPERFYAPM          1    0.909091\n",
      "4  KCNPERFYAPM          1    0.909091\n",
      "5  KRNPERFYAPM          1    0.909091\n",
      "6  KKNPERFYAPM          1    0.909091\n",
      "7  KLNPERFYAPM          1    0.909091\n",
      "8  KPCPERFYAPM          1    0.909091\n",
      "9  KPGPERFYAPM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPSSSAFFGMR          1    0.909091\n",
      "1  GPSSSAFFGMR          1    0.909091\n",
      "2  RPSSSAFFGMR          1    0.909091\n",
      "3  LPSSSAFFGMR          1    0.909091\n",
      "4  GCSSSAFFGMR          1    0.909091\n",
      "5  GRSSSAFFGMR          1    0.909091\n",
      "6  GKSSSAFFGMR          1    0.909091\n",
      "7  GLSSSAFFGMR          1    0.909091\n",
      "8  GPCSSAFFGMR          1    0.909091\n",
      "9  GPGSSAFFGMR          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSPGLIPFGRS          1    0.909091\n",
      "1  GSPGLIPFGRS          1    0.909091\n",
      "2  RSPGLIPFGRS          1    0.909091\n",
      "3  LSPGLIPFGRS          1    0.909091\n",
      "4  GCPGLIPFGRS          1    0.909091\n",
      "5  GRPGLIPFGRS          1    0.909091\n",
      "6  GKPGLIPFGRS          1    0.909091\n",
      "7  GLPGLIPFGRS          1    0.909091\n",
      "8  GSCGLIPFGRS          1    0.909091\n",
      "9  GSGGLIPFGRS          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CASGLIAFPRL          1    0.909091\n",
      "1  GASGLIAFPRL          1    0.909091\n",
      "2  RASGLIAFPRL          1    0.909091\n",
      "3  LASGLIAFPRL          1    0.909091\n",
      "4  GCSGLIAFPRL          1    0.909091\n",
      "5  GRSGLIAFPRL          1    0.909091\n",
      "6  GKSGLIAFPRL          1    0.909091\n",
      "7  GLSGLIAFPRL          1    0.909091\n",
      "8  GACGLIAFPRL          1    0.909091\n",
      "9  GAGGLIAFPRL          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CALPSALWWPG          1    0.909091\n",
      "1  GALPSALWWPG          1    0.909091\n",
      "2  RALPSALWWPG          1    0.909091\n",
      "3  LALPSALWWPG          1    0.909091\n",
      "4  MCLPSALWWPG          1    0.909091\n",
      "5  MRLPSALWWPG          1    0.909091\n",
      "6  MKLPSALWWPG          1    0.909091\n",
      "7  MLLPSALWWPG          1    0.909091\n",
      "8  MACPSALWWPG          1    0.909091\n",
      "9  MAGPSALWWPG          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPPAGPDVGPR          1    0.909091\n",
      "1  GPPAGPDVGPR          1    0.909091\n",
      "2  RPPAGPDVGPR          1    0.909091\n",
      "3  LPPAGPDVGPR          1    0.909091\n",
      "4  TCPAGPDVGPR          1    0.909091\n",
      "5  TRPAGPDVGPR          1    0.909091\n",
      "6  TKPAGPDVGPR          1    0.909091\n",
      "7  TLPAGPDVGPR          1    0.909091\n",
      "8  TPCAGPDVGPR          1    0.909091\n",
      "9  TPGAGPDVGPR          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CANAKNDFMRF          1    0.909091\n",
      "1  GANAKNDFMRF          1    0.909091\n",
      "2  RANAKNDFMRF          1    0.909091\n",
      "3  LANAKNDFMRF          1    0.909091\n",
      "4  SCNAKNDFMRF          1    0.909091\n",
      "5  SRNAKNDFMRF          1    0.909091\n",
      "6  SKNAKNDFMRF          1    0.909091\n",
      "7  SLNAKNDFMRF          1    0.909091\n",
      "8  SACAKNDFMRF          1    0.909091\n",
      "9  SAGAKNDFMRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CGQSWRPQGRF          1    0.909091\n",
      "1  GGQSWRPQGRF          1    0.909091\n",
      "2  RGQSWRPQGRF          1    0.909091\n",
      "3  LGQSWRPQGRF          1    0.909091\n",
      "4  SCQSWRPQGRF          1    0.909091\n",
      "5  SRQSWRPQGRF          1    0.909091\n",
      "6  SKQSWRPQGRF          1    0.909091\n",
      "7  SLQSWRPQGRF          1    0.909091\n",
      "8  SGCSWRPQGRF          1    0.909091\n",
      "9  SGGSWRPQGRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CRRPPGFTPFR          1    0.909091\n",
      "1  GRRPPGFTPFR          1    0.909091\n",
      "2  RRRPPGFTPFR          1    0.909091\n",
      "3  LRRPPGFTPFR          1    0.909091\n",
      "4  KCRPPGFTPFR          1    0.909091\n",
      "5  KRRPPGFTPFR          1    0.909091\n",
      "6  KKRPPGFTPFR          1    0.909091\n",
      "7  KLRPPGFTPFR          1    0.909091\n",
      "8  KRCPPGFTPFR          1    0.909091\n",
      "9  KRGPPGFTPFR          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAAGLLAFPRT          1    0.909091\n",
      "1  GAAGLLAFPRT          1    0.909091\n",
      "2  RAAGLLAFPRT          1    0.909091\n",
      "3  LAAGLLAFPRT          1    0.909091\n",
      "4  ECAGLLAFPRT          1    0.909091\n",
      "5  ERAGLLAFPRT          1    0.909091\n",
      "6  EKAGLLAFPRT          1    0.909091\n",
      "7  ELAGLLAFPRT          1    0.909091\n",
      "8  EACGLLAFPRT          1    0.909091\n",
      "9  EAGGLLAFPRT          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CAPDSSFIRDP          1    0.909091\n",
      "1  GAPDSSFIRDP          1    0.909091\n",
      "2  RAPDSSFIRDP          1    0.909091\n",
      "3  LAPDSSFIRDP          1    0.909091\n",
      "4  PCPDSSFIRDP          1    0.909091\n",
      "5  PRPDSSFIRDP          1    0.909091\n",
      "6  PKPDSSFIRDP          1    0.909091\n",
      "7  PLPDSSFIRDP          1    0.909091\n",
      "8  PACDSSFIRDP          1    0.909091\n",
      "9  PAGDSSFIRDP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CPRPHQFFGLM          1    0.909091\n",
      "1  GPRPHQFFGLM          1    0.909091\n",
      "2  RPRPHQFFGLM          1    0.909091\n",
      "3  LPRPHQFFGLM          1    0.909091\n",
      "4  KCRPHQFFGLM          1    0.909091\n",
      "5  KRRPHQFFGLM          1    0.909091\n",
      "6  KKRPHQFFGLM          1    0.909091\n",
      "7  KLRPHQFFGLM          1    0.909091\n",
      "8  KPCPHQFFGLM          1    0.909091\n",
      "9  KPGPHQFFGLM          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CLPPCAYKGTC          1    0.909091\n",
      "1  GLPPCAYKGTC          1    0.909091\n",
      "2  RLPPCAYKGTC          1    0.909091\n",
      "3  LLPPCAYKGTC          1    0.909091\n",
      "4  FCPPCAYKGTC          1    0.909091\n",
      "5  FRPPCAYKGTC          1    0.909091\n",
      "6  FKPPCAYKGTC          1    0.909091\n",
      "7  FLPPCAYKGTC          1    0.909091\n",
      "8  FLCPCAYKGTC          1    0.909091\n",
      "9  FLGPCAYKGTC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CTCCGSKVFCC          1    0.909091\n",
      "1  GTCCGSKVFCC          1    0.909091\n",
      "2  RTCCGSKVFCC          1    0.909091\n",
      "3  LTCCGSKVFCC          1    0.909091\n",
      "4  QCCCGSKVFCC          1    0.909091\n",
      "5  QRCCGSKVFCC          1    0.909091\n",
      "6  QKCCGSKVFCC          1    0.909091\n",
      "7  QLCCGSKVFCC          1    0.909091\n",
      "8  QTCCGSKVFCC          1    0.909091\n",
      "9  QTGCGSKVFCC          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CNRSPSLRLRF          1    0.909091\n",
      "1  GNRSPSLRLRF          1    0.909091\n",
      "2  RNRSPSLRLRF          1    0.909091\n",
      "3  LNRSPSLRLRF          1    0.909091\n",
      "4  SCRSPSLRLRF          1    0.909091\n",
      "5  SRRSPSLRLRF          1    0.909091\n",
      "6  SKRSPSLRLRF          1    0.909091\n",
      "7  SLRSPSLRLRF          1    0.909091\n",
      "8  SNCSPSLRLRF          1    0.909091\n",
      "9  SNGSPSLRLRF          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CSSGLIPFGRT          1    0.909091\n",
      "1  GSSGLIPFGRT          1    0.909091\n",
      "2  RSSGLIPFGRT          1    0.909091\n",
      "3  LSSGLIPFGRT          1    0.909091\n",
      "4  GCSGLIPFGRT          1    0.909091\n",
      "5  GRSGLIPFGRT          1    0.909091\n",
      "6  GKSGLIPFGRT          1    0.909091\n",
      "7  GLSGLIPFGRT          1    0.909091\n",
      "8  GSCGLIPFGRT          1    0.909091\n",
      "9  GSGGLIPFGRT          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "       peptide  mutations  similarity\n",
      "0  CVPDSSFLRDP          1    0.909091\n",
      "1  GVPDSSFLRDP          1    0.909091\n",
      "2  RVPDSSFLRDP          1    0.909091\n",
      "3  LVPDSSFLRDP          1    0.909091\n",
      "4  PCPDSSFLRDP          1    0.909091\n",
      "5  PRPDSSFLRDP          1    0.909091\n",
      "6  PKPDSSFLRDP          1    0.909091\n",
      "7  PLPDSSFLRDP          1    0.909091\n",
      "8  PVCDSSFLRDP          1    0.909091\n",
      "9  PVGDSSFLRDP          1    0.909091\n",
      "# Samples =  11484\n",
      "val_loader length: 12\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([220, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([220, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([220, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([220, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 220 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([220, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([220, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([220, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CEAAGLLPFPRV          1    0.916667\n",
      "1  GEAAGLLPFPRV          1    0.916667\n",
      "2  REAAGLLPFPRV          1    0.916667\n",
      "3  LEAAGLLPFPRV          1    0.916667\n",
      "4  ACAAGLLPFPRV          1    0.916667\n",
      "5  ARAAGLLPFPRV          1    0.916667\n",
      "6  AKAAGLLPFPRV          1    0.916667\n",
      "7  ALAAGLLPFPRV          1    0.916667\n",
      "8  AECAGLLPFPRV          1    0.916667\n",
      "9  AEGAGLLPFPRV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPENENEEALHE          1    0.916667\n",
      "1  GPENENEEALHE          1    0.916667\n",
      "2  RPENENEEALHE          1    0.916667\n",
      "3  LPENENEEALHE          1    0.916667\n",
      "4  KCENENEEALHE          1    0.916667\n",
      "5  KRENENEEALHE          1    0.916667\n",
      "6  KKENENEEALHE          1    0.916667\n",
      "7  KLENENEEALHE          1    0.916667\n",
      "8  KPCNENEEALHE          1    0.916667\n",
      "9  KPGNENEEALHE          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPMGWVPVFYRF          1    0.916667\n",
      "1  GPMGWVPVFYRF          1    0.916667\n",
      "2  RPMGWVPVFYRF          1    0.916667\n",
      "3  LPMGWVPVFYRF          1    0.916667\n",
      "4  GCMGWVPVFYRF          1    0.916667\n",
      "5  GRMGWVPVFYRF          1    0.916667\n",
      "6  GKMGWVPVFYRF          1    0.916667\n",
      "7  GLMGWVPVFYRF          1    0.916667\n",
      "8  GPCGWVPVFYRF          1    0.916667\n",
      "9  GPGGWVPVFYRF          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CCCSDPRCKHQC          1    0.916667\n",
      "1  GCCSDPRCKHQC          1    0.916667\n",
      "2  RCCSDPRCKHQC          1    0.916667\n",
      "3  LCCSDPRCKHQC          1    0.916667\n",
      "4  GCCSDPRCKHQC          1    0.916667\n",
      "5  GRCSDPRCKHQC          1    0.916667\n",
      "6  GKCSDPRCKHQC          1    0.916667\n",
      "7  GLCSDPRCKHQC          1    0.916667\n",
      "8  GCCSDPRCKHQC          1    0.916667\n",
      "9  GCGSDPRCKHQC          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CCCSDPRCRYRC          1    0.916667\n",
      "1  GCCSDPRCRYRC          1    0.916667\n",
      "2  RCCSDPRCRYRC          1    0.916667\n",
      "3  LCCSDPRCRYRC          1    0.916667\n",
      "4  GCCSDPRCRYRC          1    0.916667\n",
      "5  GRCSDPRCRYRC          1    0.916667\n",
      "6  GKCSDPRCRYRC          1    0.916667\n",
      "7  GLCSDPRCRYRC          1    0.916667\n",
      "8  GCCSDPRCRYRC          1    0.916667\n",
      "9  GCGSDPRCRYRC          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CGNTECFWKYCV          1    0.916667\n",
      "1  GGNTECFWKYCV          1    0.916667\n",
      "2  RGNTECFWKYCV          1    0.916667\n",
      "3  LGNTECFWKYCV          1    0.916667\n",
      "4  GCNTECFWKYCV          1    0.916667\n",
      "5  GRNTECFWKYCV          1    0.916667\n",
      "6  GKNTECFWKYCV          1    0.916667\n",
      "7  GLNTECFWKYCV          1    0.916667\n",
      "8  GGCTECFWKYCV          1    0.916667\n",
      "9  GGGTECFWKYCV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CLASDDYGHMRF          1    0.916667\n",
      "1  GLASDDYGHMRF          1    0.916667\n",
      "2  RLASDDYGHMRF          1    0.916667\n",
      "3  LLASDDYGHMRF          1    0.916667\n",
      "4  QCASDDYGHMRF          1    0.916667\n",
      "5  QRASDDYGHMRF          1    0.916667\n",
      "6  QKASDDYGHMRF          1    0.916667\n",
      "7  QLASDDYGHMRF          1    0.916667\n",
      "8  QLCSDDYGHMRF          1    0.916667\n",
      "9  QLGSDDYGHMRF          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSLTGLISMPRT          1    0.916667\n",
      "1  GSLTGLISMPRT          1    0.916667\n",
      "2  RSLTGLISMPRT          1    0.916667\n",
      "3  LSLTGLISMPRT          1    0.916667\n",
      "4  GCLTGLISMPRT          1    0.916667\n",
      "5  GRLTGLISMPRT          1    0.916667\n",
      "6  GKLTGLISMPRT          1    0.916667\n",
      "7  GLLTGLISMPRT          1    0.916667\n",
      "8  GSCTGLISMPRT          1    0.916667\n",
      "9  GSGTGLISMPRT          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CGTADCFWKYCV          1    0.916667\n",
      "1  GGTADCFWKYCV          1    0.916667\n",
      "2  RGTADCFWKYCV          1    0.916667\n",
      "3  LGTADCFWKYCV          1    0.916667\n",
      "4  ACTADCFWKYCV          1    0.916667\n",
      "5  ARTADCFWKYCV          1    0.916667\n",
      "6  AKTADCFWKYCV          1    0.916667\n",
      "7  ALTADCFWKYCV          1    0.916667\n",
      "8  AGCADCFWKYCV          1    0.916667\n",
      "9  AGGADCFWKYCV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CNSCTPKPSCFF          1    0.916667\n",
      "1  GNSCTPKPSCFF          1    0.916667\n",
      "2  RNSCTPKPSCFF          1    0.916667\n",
      "3  LNSCTPKPSCFF          1    0.916667\n",
      "4  DCSCTPKPSCFF          1    0.916667\n",
      "5  DRSCTPKPSCFF          1    0.916667\n",
      "6  DKSCTPKPSCFF          1    0.916667\n",
      "7  DLSCTPKPSCFF          1    0.916667\n",
      "8  DNCCTPKPSCFF          1    0.916667\n",
      "9  DNGCTPKPSCFF          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CVCCGVSFCYPC          1    0.916667\n",
      "1  GVCCGVSFCYPC          1    0.916667\n",
      "2  RVCCGVSFCYPC          1    0.916667\n",
      "3  LVCCGVSFCYPC          1    0.916667\n",
      "4  GCCCGVSFCYPC          1    0.916667\n",
      "5  GRCCGVSFCYPC          1    0.916667\n",
      "6  GKCCGVSFCYPC          1    0.916667\n",
      "7  GLCCGVSFCYPC          1    0.916667\n",
      "8  GVCCGVSFCYPC          1    0.916667\n",
      "9  GVGCGVSFCYPC          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CGSSGLISVPRV          1    0.916667\n",
      "1  GGSSGLISVPRV          1    0.916667\n",
      "2  RGSSGLISVPRV          1    0.916667\n",
      "3  LGSSGLISVPRV          1    0.916667\n",
      "4  GCSSGLISVPRV          1    0.916667\n",
      "5  GRSSGLISVPRV          1    0.916667\n",
      "6  GKSSGLISVPRV          1    0.916667\n",
      "7  GLSSGLISVPRV          1    0.916667\n",
      "8  GGCSGLISVPRV          1    0.916667\n",
      "9  GGGSGLISVPRV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CAAGLIPFPRVG          1    0.916667\n",
      "1  GAAGLIPFPRVG          1    0.916667\n",
      "2  RAAGLIPFPRVG          1    0.916667\n",
      "3  LAAGLIPFPRVG          1    0.916667\n",
      "4  ECAGLIPFPRVG          1    0.916667\n",
      "5  ERAGLIPFPRVG          1    0.916667\n",
      "6  EKAGLIPFPRVG          1    0.916667\n",
      "7  ELAGLIPFPRVG          1    0.916667\n",
      "8  EACGLIPFPRVG          1    0.916667\n",
      "9  EAGGLIPFPRVG          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSRLFFVCRKVR          1    0.916667\n",
      "1  GSRLFFVCRKVR          1    0.916667\n",
      "2  RSRLFFVCRKVR          1    0.916667\n",
      "3  LSRLFFVCRKVR          1    0.916667\n",
      "4  MCRLFFVCRKVR          1    0.916667\n",
      "5  MRRLFFVCRKVR          1    0.916667\n",
      "6  MKRLFFVCRKVR          1    0.916667\n",
      "7  MLRLFFVCRKVR          1    0.916667\n",
      "8  MSCLFFVCRKVR          1    0.916667\n",
      "9  MSGLFFVCRKVR          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CELCWLTTIHGS          1    0.916667\n",
      "1  GELCWLTTIHGS          1    0.916667\n",
      "2  RELCWLTTIHGS          1    0.916667\n",
      "3  LELCWLTTIHGS          1    0.916667\n",
      "4  MCLCWLTTIHGS          1    0.916667\n",
      "5  MRLCWLTTIHGS          1    0.916667\n",
      "6  MKLCWLTTIHGS          1    0.916667\n",
      "7  MLLCWLTTIHGS          1    0.916667\n",
      "8  MECCWLTTIHGS          1    0.916667\n",
      "9  MEGCWLTTIHGS          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CARPRPGPKIPP          1    0.916667\n",
      "1  GARPRPGPKIPP          1    0.916667\n",
      "2  RARPRPGPKIPP          1    0.916667\n",
      "3  LARPRPGPKIPP          1    0.916667\n",
      "4  QCRPRPGPKIPP          1    0.916667\n",
      "5  QRRPRPGPKIPP          1    0.916667\n",
      "6  QKRPRPGPKIPP          1    0.916667\n",
      "7  QLRPRPGPKIPP          1    0.916667\n",
      "8  QACPRPGPKIPP          1    0.916667\n",
      "9  QAGPRPGPKIPP          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CHLSHDVYSPRL          1    0.916667\n",
      "1  GHLSHDVYSPRL          1    0.916667\n",
      "2  RHLSHDVYSPRL          1    0.916667\n",
      "3  LHLSHDVYSPRL          1    0.916667\n",
      "4  DCLSHDVYSPRL          1    0.916667\n",
      "5  DRLSHDVYSPRL          1    0.916667\n",
      "6  DKLSHDVYSPRL          1    0.916667\n",
      "7  DLLSHDVYSPRL          1    0.916667\n",
      "8  DHCSHDVYSPRL          1    0.916667\n",
      "9  DHGSHDVYSPRL          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CCCPTMPECCRI          1    0.916667\n",
      "1  GCCPTMPECCRI          1    0.916667\n",
      "2  RCCPTMPECCRI          1    0.916667\n",
      "3  LCCPTMPECCRI          1    0.916667\n",
      "4  QCCPTMPECCRI          1    0.916667\n",
      "5  QRCPTMPECCRI          1    0.916667\n",
      "6  QKCPTMPECCRI          1    0.916667\n",
      "7  QLCPTMPECCRI          1    0.916667\n",
      "8  QCCPTMPECCRI          1    0.916667\n",
      "9  QCGPTMPECCRI          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPPQPADNFIRF          1    0.916667\n",
      "1  GPPQPADNFIRF          1    0.916667\n",
      "2  RPPQPADNFIRF          1    0.916667\n",
      "3  LPPQPADNFIRF          1    0.916667\n",
      "4  TCPQPADNFIRF          1    0.916667\n",
      "5  TRPQPADNFIRF          1    0.916667\n",
      "6  TKPQPADNFIRF          1    0.916667\n",
      "7  TLPQPADNFIRF          1    0.916667\n",
      "8  TPCQPADNFIRF          1    0.916667\n",
      "9  TPGQPADNFIRF          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CCCPIDEESCCS          1    0.916667\n",
      "1  GCCPIDEESCCS          1    0.916667\n",
      "2  RCCPIDEESCCS          1    0.916667\n",
      "3  LCCPIDEESCCS          1    0.916667\n",
      "4  NCCPIDEESCCS          1    0.916667\n",
      "5  NRCPIDEESCCS          1    0.916667\n",
      "6  NKCPIDEESCCS          1    0.916667\n",
      "7  NLCPIDEESCCS          1    0.916667\n",
      "8  NCCPIDEESCCS          1    0.916667\n",
      "9  NCGPIDEESCCS          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPCCGYRMCVPC          1    0.916667\n",
      "1  GPCCGYRMCVPC          1    0.916667\n",
      "2  RPCCGYRMCVPC          1    0.916667\n",
      "3  LPCCGYRMCVPC          1    0.916667\n",
      "4  DCCCGYRMCVPC          1    0.916667\n",
      "5  DRCCGYRMCVPC          1    0.916667\n",
      "6  DKCCGYRMCVPC          1    0.916667\n",
      "7  DLCCGYRMCVPC          1    0.916667\n",
      "8  DPCCGYRMCVPC          1    0.916667\n",
      "9  DPGCGYRMCVPC          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPMEDPLEIIRI          1    0.916667\n",
      "1  GPMEDPLEIIRI          1    0.916667\n",
      "2  RPMEDPLEIIRI          1    0.916667\n",
      "3  LPMEDPLEIIRI          1    0.916667\n",
      "4  GCMEDPLEIIRI          1    0.916667\n",
      "5  GRMEDPLEIIRI          1    0.916667\n",
      "6  GKMEDPLEIIRI          1    0.916667\n",
      "7  GLMEDPLEIIRI          1    0.916667\n",
      "8  GPCEDPLEIIRI          1    0.916667\n",
      "9  GPGEDPLEIIRI          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CQWPRDPAPIPP          1    0.916667\n",
      "1  GQWPRDPAPIPP          1    0.916667\n",
      "2  RQWPRDPAPIPP          1    0.916667\n",
      "3  LQWPRDPAPIPP          1    0.916667\n",
      "4  QCWPRDPAPIPP          1    0.916667\n",
      "5  QRWPRDPAPIPP          1    0.916667\n",
      "6  QKWPRDPAPIPP          1    0.916667\n",
      "7  QLWPRDPAPIPP          1    0.916667\n",
      "8  QQCPRDPAPIPP          1    0.916667\n",
      "9  QQGPRDPAPIPP          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CGFLPIYRRPAS          1    0.916667\n",
      "1  GGFLPIYRRPAS          1    0.916667\n",
      "2  RGFLPIYRRPAS          1    0.916667\n",
      "3  LGFLPIYRRPAS          1    0.916667\n",
      "4  FCFLPIYRRPAS          1    0.916667\n",
      "5  FRFLPIYRRPAS          1    0.916667\n",
      "6  FKFLPIYRRPAS          1    0.916667\n",
      "7  FLFLPIYRRPAS          1    0.916667\n",
      "8  FGCLPIYRRPAS          1    0.916667\n",
      "9  FGGLPIYRRPAS          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CYRKPPFNGSIF          1    0.916667\n",
      "1  GYRKPPFNGSIF          1    0.916667\n",
      "2  RYRKPPFNGSIF          1    0.916667\n",
      "3  LYRKPPFNGSIF          1    0.916667\n",
      "4  GCRKPPFNGSIF          1    0.916667\n",
      "5  GRRKPPFNGSIF          1    0.916667\n",
      "6  GKRKPPFNGSIF          1    0.916667\n",
      "7  GLRKPPFNGSIF          1    0.916667\n",
      "8  GYCKPPFNGSIF          1    0.916667\n",
      "9  GYGKPPFNGSIF          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CEPKPDQFVGLM          1    0.916667\n",
      "1  GEPKPDQFVGLM          1    0.916667\n",
      "2  REPKPDQFVGLM          1    0.916667\n",
      "3  LEPKPDQFVGLM          1    0.916667\n",
      "4  DCPKPDQFVGLM          1    0.916667\n",
      "5  DRPKPDQFVGLM          1    0.916667\n",
      "6  DKPKPDQFVGLM          1    0.916667\n",
      "7  DLPKPDQFVGLM          1    0.916667\n",
      "8  DECKPDQFVGLM          1    0.916667\n",
      "9  DEGKPDQFVGLM          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CNWPHPPMPPAP          1    0.916667\n",
      "1  GNWPHPPMPPAP          1    0.916667\n",
      "2  RNWPHPPMPPAP          1    0.916667\n",
      "3  LNWPHPPMPPAP          1    0.916667\n",
      "4  QCWPHPPMPPAP          1    0.916667\n",
      "5  QRWPHPPMPPAP          1    0.916667\n",
      "6  QKWPHPPMPPAP          1    0.916667\n",
      "7  QLWPHPPMPPAP          1    0.916667\n",
      "8  QNCPHPPMPPAP          1    0.916667\n",
      "9  QNGPHPPMPPAP          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CAVPAAQFSPRL          1    0.916667\n",
      "1  GAVPAAQFSPRL          1    0.916667\n",
      "2  RAVPAAQFSPRL          1    0.916667\n",
      "3  LAVPAAQFSPRL          1    0.916667\n",
      "4  GCVPAAQFSPRL          1    0.916667\n",
      "5  GRVPAAQFSPRL          1    0.916667\n",
      "6  GKVPAAQFSPRL          1    0.916667\n",
      "7  GLVPAAQFSPRL          1    0.916667\n",
      "8  GACPAAQFSPRL          1    0.916667\n",
      "9  GAGPAAQFSPRL          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CRPPGFSPFRIV          1    0.916667\n",
      "1  GRPPGFSPFRIV          1    0.916667\n",
      "2  RRPPGFSPFRIV          1    0.916667\n",
      "3  LRPPGFSPFRIV          1    0.916667\n",
      "4  ACPPGFSPFRIV          1    0.916667\n",
      "5  ARPPGFSPFRIV          1    0.916667\n",
      "6  AKPPGFSPFRIV          1    0.916667\n",
      "7  ALPPGFSPFRIV          1    0.916667\n",
      "8  ARCPGFSPFRIV          1    0.916667\n",
      "9  ARGPGFSPFRIV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CERRAMGFVGMR          1    0.916667\n",
      "1  GERRAMGFVGMR          1    0.916667\n",
      "2  RERRAMGFVGMR          1    0.916667\n",
      "3  LERRAMGFVGMR          1    0.916667\n",
      "4  QCRRAMGFVGMR          1    0.916667\n",
      "5  QRRRAMGFVGMR          1    0.916667\n",
      "6  QKRRAMGFVGMR          1    0.916667\n",
      "7  QLRRAMGFVGMR          1    0.916667\n",
      "8  QECRAMGFVGMR          1    0.916667\n",
      "9  QEGRAMGFVGMR          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CTFGQGTKVEIK          1    0.916667\n",
      "1  GTFGQGTKVEIK          1    0.916667\n",
      "2  RTFGQGTKVEIK          1    0.916667\n",
      "3  LTFGQGTKVEIK          1    0.916667\n",
      "4  WCFGQGTKVEIK          1    0.916667\n",
      "5  WRFGQGTKVEIK          1    0.916667\n",
      "6  WKFGQGTKVEIK          1    0.916667\n",
      "7  WLFGQGTKVEIK          1    0.916667\n",
      "8  WTCGQGTKVEIK          1    0.916667\n",
      "9  WTGGQGTKVEIK          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSSSGLISMPRV          1    0.916667\n",
      "1  GSSSGLISMPRV          1    0.916667\n",
      "2  RSSSGLISMPRV          1    0.916667\n",
      "3  LSSSGLISMPRV          1    0.916667\n",
      "4  GCSSGLISMPRV          1    0.916667\n",
      "5  GRSSGLISMPRV          1    0.916667\n",
      "6  GKSSGLISMPRV          1    0.916667\n",
      "7  GLSSGLISMPRV          1    0.916667\n",
      "8  GSCSGLISMPRV          1    0.916667\n",
      "9  GSGSGLISMPRV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CKKDKDRFYGLM          1    0.916667\n",
      "1  GKKDKDRFYGLM          1    0.916667\n",
      "2  RKKDKDRFYGLM          1    0.916667\n",
      "3  LKKDKDRFYGLM          1    0.916667\n",
      "4  QCKDKDRFYGLM          1    0.916667\n",
      "5  QRKDKDRFYGLM          1    0.916667\n",
      "6  QKKDKDRFYGLM          1    0.916667\n",
      "7  QLKDKDRFYGLM          1    0.916667\n",
      "8  QKCDKDRFYGLM          1    0.916667\n",
      "9  QKGDKDRFYGLM          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CNFSDCFWKYCV          1    0.916667\n",
      "1  GNFSDCFWKYCV          1    0.916667\n",
      "2  RNFSDCFWKYCV          1    0.916667\n",
      "3  LNFSDCFWKYCV          1    0.916667\n",
      "4  NCFSDCFWKYCV          1    0.916667\n",
      "5  NRFSDCFWKYCV          1    0.916667\n",
      "6  NKFSDCFWKYCV          1    0.916667\n",
      "7  NLFSDCFWKYCV          1    0.916667\n",
      "8  NNCSDCFWKYCV          1    0.916667\n",
      "9  NNGSDCFWKYCV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CCCSDPRCKHEC          1    0.916667\n",
      "1  GCCSDPRCKHEC          1    0.916667\n",
      "2  RCCSDPRCKHEC          1    0.916667\n",
      "3  LCCSDPRCKHEC          1    0.916667\n",
      "4  GCCSDPRCKHEC          1    0.916667\n",
      "5  GRCSDPRCKHEC          1    0.916667\n",
      "6  GKCSDPRCKHEC          1    0.916667\n",
      "7  GLCSDPRCKHEC          1    0.916667\n",
      "8  GCCSDPRCKHEC          1    0.916667\n",
      "9  GCGSDPRCKHEC          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CCSCQKHFSCCD          1    0.916667\n",
      "1  GCSCQKHFSCCD          1    0.916667\n",
      "2  RCSCQKHFSCCD          1    0.916667\n",
      "3  LCSCQKHFSCCD          1    0.916667\n",
      "4  SCSCQKHFSCCD          1    0.916667\n",
      "5  SRSCQKHFSCCD          1    0.916667\n",
      "6  SKSCQKHFSCCD          1    0.916667\n",
      "7  SLSCQKHFSCCD          1    0.916667\n",
      "8  SCCCQKHFSCCD          1    0.916667\n",
      "9  SCGCQKHFSCCD          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSASGLISMPRV          1    0.916667\n",
      "1  GSASGLISMPRV          1    0.916667\n",
      "2  RSASGLISMPRV          1    0.916667\n",
      "3  LSASGLISMPRV          1    0.916667\n",
      "4  GCASGLISMPRV          1    0.916667\n",
      "5  GRASGLISMPRV          1    0.916667\n",
      "6  GKASGLISMPRV          1    0.916667\n",
      "7  GLASGLISMPRV          1    0.916667\n",
      "8  GSCSGLISMPRV          1    0.916667\n",
      "9  GSGSGLISMPRV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CLGPPPRPQIPP          1    0.916667\n",
      "1  GLGPPPRPQIPP          1    0.916667\n",
      "2  RLGPPPRPQIPP          1    0.916667\n",
      "3  LLGPPPRPQIPP          1    0.916667\n",
      "4  QCGPPPRPQIPP          1    0.916667\n",
      "5  QRGPPPRPQIPP          1    0.916667\n",
      "6  QKGPPPRPQIPP          1    0.916667\n",
      "7  QLGPPPRPQIPP          1    0.916667\n",
      "8  QLCPPPRPQIPP          1    0.916667\n",
      "9  QLGPPPRPQIPP          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CAASESGFRRDP          1    0.916667\n",
      "1  GAASESGFRRDP          1    0.916667\n",
      "2  RAASESGFRRDP          1    0.916667\n",
      "3  LAASESGFRRDP          1    0.916667\n",
      "4  PCASESGFRRDP          1    0.916667\n",
      "5  PRASESGFRRDP          1    0.916667\n",
      "6  PKASESGFRRDP          1    0.916667\n",
      "7  PLASESGFRRDP          1    0.916667\n",
      "8  PACSESGFRRDP          1    0.916667\n",
      "9  PAGSESGFRRDP          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPPDPDRFYGMM          1    0.916667\n",
      "1  GPPDPDRFYGMM          1    0.916667\n",
      "2  RPPDPDRFYGMM          1    0.916667\n",
      "3  LPPDPDRFYGMM          1    0.916667\n",
      "4  DCPDPDRFYGMM          1    0.916667\n",
      "5  DRPDPDRFYGMM          1    0.916667\n",
      "6  DKPDPDRFYGMM          1    0.916667\n",
      "7  DLPDPDRFYGMM          1    0.916667\n",
      "8  DPCDPDRFYGMM          1    0.916667\n",
      "9  DPGDPDRFYGMM          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CGWAWPRPQIPP          1    0.916667\n",
      "1  GGWAWPRPQIPP          1    0.916667\n",
      "2  RGWAWPRPQIPP          1    0.916667\n",
      "3  LGWAWPRPQIPP          1    0.916667\n",
      "4  QCWAWPRPQIPP          1    0.916667\n",
      "5  QRWAWPRPQIPP          1    0.916667\n",
      "6  QKWAWPRPQIPP          1    0.916667\n",
      "7  QLWAWPRPQIPP          1    0.916667\n",
      "8  QGCAWPRPQIPP          1    0.916667\n",
      "9  QGGAWPRPQIPP          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSSGGMIPFPRV          1    0.916667\n",
      "1  GSSGGMIPFPRV          1    0.916667\n",
      "2  RSSGGMIPFPRV          1    0.916667\n",
      "3  LSSGGMIPFPRV          1    0.916667\n",
      "4  GCSGGMIPFPRV          1    0.916667\n",
      "5  GRSGGMIPFPRV          1    0.916667\n",
      "6  GKSGGMIPFPRV          1    0.916667\n",
      "7  GLSGGMIPFPRV          1    0.916667\n",
      "8  GSCGGMIPFPRV          1    0.916667\n",
      "9  GSGGGMIPFPRV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CVPKSDQFVGLM          1    0.916667\n",
      "1  GVPKSDQFVGLM          1    0.916667\n",
      "2  RVPKSDQFVGLM          1    0.916667\n",
      "3  LVPKSDQFVGLM          1    0.916667\n",
      "4  DCPKSDQFVGLM          1    0.916667\n",
      "5  DRPKSDQFVGLM          1    0.916667\n",
      "6  DKPKSDQFVGLM          1    0.916667\n",
      "7  DLPKSDQFVGLM          1    0.916667\n",
      "8  DVCKSDQFVGLM          1    0.916667\n",
      "9  DVGKSDQFVGLM          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CHMSHDVYSPRL          1    0.916667\n",
      "1  GHMSHDVYSPRL          1    0.916667\n",
      "2  RHMSHDVYSPRL          1    0.916667\n",
      "3  LHMSHDVYSPRL          1    0.916667\n",
      "4  DCMSHDVYSPRL          1    0.916667\n",
      "5  DRMSHDVYSPRL          1    0.916667\n",
      "6  DKMSHDVYSPRL          1    0.916667\n",
      "7  DLMSHDVYSPRL          1    0.916667\n",
      "8  DHCSHDVYSPRL          1    0.916667\n",
      "9  DHGSHDVYSPRL          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSGADCFWKYCV          1    0.916667\n",
      "1  GSGADCFWKYCV          1    0.916667\n",
      "2  RSGADCFWKYCV          1    0.916667\n",
      "3  LSGADCFWKYCV          1    0.916667\n",
      "4  GCGADCFWKYCV          1    0.916667\n",
      "5  GRGADCFWKYCV          1    0.916667\n",
      "6  GKGADCFWKYCV          1    0.916667\n",
      "7  GLGADCFWKYCV          1    0.916667\n",
      "8  GSCADCFWKYCV          1    0.916667\n",
      "9  GSGADCFWKYCV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CHDPSAPGNGYC          1    0.916667\n",
      "1  GHDPSAPGNGYC          1    0.916667\n",
      "2  RHDPSAPGNGYC          1    0.916667\n",
      "3  LHDPSAPGNGYC          1    0.916667\n",
      "4  ECDPSAPGNGYC          1    0.916667\n",
      "5  ERDPSAPGNGYC          1    0.916667\n",
      "6  EKDPSAPGNGYC          1    0.916667\n",
      "7  ELDPSAPGNGYC          1    0.916667\n",
      "8  EHCPSAPGNGYC          1    0.916667\n",
      "9  EHGPSAPGNGYC          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CHLPHDVYSPRL          1    0.916667\n",
      "1  GHLPHDVYSPRL          1    0.916667\n",
      "2  RHLPHDVYSPRL          1    0.916667\n",
      "3  LHLPHDVYSPRL          1    0.916667\n",
      "4  DCLPHDVYSPRL          1    0.916667\n",
      "5  DRLPHDVYSPRL          1    0.916667\n",
      "6  DKLPHDVYSPRL          1    0.916667\n",
      "7  DLLPHDVYSPRL          1    0.916667\n",
      "8  DHCPHDVYSPRL          1    0.916667\n",
      "9  DHGPHDVYSPRL          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CGSSGLISMPRV          1    0.916667\n",
      "1  GGSSGLISMPRV          1    0.916667\n",
      "2  RGSSGLISMPRV          1    0.916667\n",
      "3  LGSSGLISMPRV          1    0.916667\n",
      "4  GCSSGLISMPRV          1    0.916667\n",
      "5  GRSSGLISMPRV          1    0.916667\n",
      "6  GKSSGLISMPRV          1    0.916667\n",
      "7  GLSSGLISMPRV          1    0.916667\n",
      "8  GGCSGLISMPRV          1    0.916667\n",
      "9  GGGSGLISMPRV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPPQPSDNFIRF          1    0.916667\n",
      "1  GPPQPSDNFIRF          1    0.916667\n",
      "2  RPPQPSDNFIRF          1    0.916667\n",
      "3  LPPQPSDNFIRF          1    0.916667\n",
      "4  ACPQPSDNFIRF          1    0.916667\n",
      "5  ARPQPSDNFIRF          1    0.916667\n",
      "6  AKPQPSDNFIRF          1    0.916667\n",
      "7  ALPQPSDNFIRF          1    0.916667\n",
      "8  APCQPSDNFIRF          1    0.916667\n",
      "9  APGQPSDNFIRF          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CTCCGYRMCVPC          1    0.916667\n",
      "1  GTCCGYRMCVPC          1    0.916667\n",
      "2  RTCCGYRMCVPC          1    0.916667\n",
      "3  LTCCGYRMCVPC          1    0.916667\n",
      "4  QCCCGYRMCVPC          1    0.916667\n",
      "5  QRCCGYRMCVPC          1    0.916667\n",
      "6  QKCCGYRMCVPC          1    0.916667\n",
      "7  QLCCGYRMCVPC          1    0.916667\n",
      "8  QTCCGYRMCVPC          1    0.916667\n",
      "9  QTGCGYRMCVPC          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CTPHDEEVDSSD          1    0.916667\n",
      "1  GTPHDEEVDSSD          1    0.916667\n",
      "2  RTPHDEEVDSSD          1    0.916667\n",
      "3  LTPHDEEVDSSD          1    0.916667\n",
      "4  MCPHDEEVDSSD          1    0.916667\n",
      "5  MRPHDEEVDSSD          1    0.916667\n",
      "6  MKPHDEEVDSSD          1    0.916667\n",
      "7  MLPHDEEVDSSD          1    0.916667\n",
      "8  MTCHDEEVDSSD          1    0.916667\n",
      "9  MTGHDEEVDSSD          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CKLCWQKSIHGS          1    0.916667\n",
      "1  GKLCWQKSIHGS          1    0.916667\n",
      "2  RKLCWQKSIHGS          1    0.916667\n",
      "3  LKLCWQKSIHGS          1    0.916667\n",
      "4  MCLCWQKSIHGS          1    0.916667\n",
      "5  MRLCWQKSIHGS          1    0.916667\n",
      "6  MKLCWQKSIHGS          1    0.916667\n",
      "7  MLLCWQKSIHGS          1    0.916667\n",
      "8  MKCCWQKSIHGS          1    0.916667\n",
      "9  MKGCWQKSIHGS          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CRFCWQKSIHGS          1    0.916667\n",
      "1  GRFCWQKSIHGS          1    0.916667\n",
      "2  RRFCWQKSIHGS          1    0.916667\n",
      "3  LRFCWQKSIHGS          1    0.916667\n",
      "4  MCFCWQKSIHGS          1    0.916667\n",
      "5  MRFCWQKSIHGS          1    0.916667\n",
      "6  MKFCWQKSIHGS          1    0.916667\n",
      "7  MLFCWQKSIHGS          1    0.916667\n",
      "8  MRCCWQKSIHGS          1    0.916667\n",
      "9  MRGCWQKSIHGS          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSSGGLITFGRT          1    0.916667\n",
      "1  GSSGGLITFGRT          1    0.916667\n",
      "2  RSSGGLITFGRT          1    0.916667\n",
      "3  LSSGGLITFGRT          1    0.916667\n",
      "4  GCSGGLITFGRT          1    0.916667\n",
      "5  GRSGGLITFGRT          1    0.916667\n",
      "6  GKSGGLITFGRT          1    0.916667\n",
      "7  GLSGGLITFGRT          1    0.916667\n",
      "8  GSCGGLITFGRT          1    0.916667\n",
      "9  GSGGGLITFGRT          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSNTECFWKYCV          1    0.916667\n",
      "1  GSNTECFWKYCV          1    0.916667\n",
      "2  RSNTECFWKYCV          1    0.916667\n",
      "3  LSNTECFWKYCV          1    0.916667\n",
      "4  GCNTECFWKYCV          1    0.916667\n",
      "5  GRNTECFWKYCV          1    0.916667\n",
      "6  GKNTECFWKYCV          1    0.916667\n",
      "7  GLNTECFWKYCV          1    0.916667\n",
      "8  GSCTECFWKYCV          1    0.916667\n",
      "9  GSGTECFWKYCV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CGSSGLIAFPRL          1    0.916667\n",
      "1  GGSSGLIAFPRL          1    0.916667\n",
      "2  RGSSGLIAFPRL          1    0.916667\n",
      "3  LGSSGLIAFPRL          1    0.916667\n",
      "4  GCSSGLIAFPRL          1    0.916667\n",
      "5  GRSSGLIAFPRL          1    0.916667\n",
      "6  GKSSGLIAFPRL          1    0.916667\n",
      "7  GLSSGLIAFPRL          1    0.916667\n",
      "8  GGCSGLIAFPRL          1    0.916667\n",
      "9  GGGSGLIAFPRL          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CRPPGFSPFRID          1    0.916667\n",
      "1  GRPPGFSPFRID          1    0.916667\n",
      "2  RRPPGFSPFRID          1    0.916667\n",
      "3  LRPPGFSPFRID          1    0.916667\n",
      "4  GCPPGFSPFRID          1    0.916667\n",
      "5  GRPPGFSPFRID          1    0.916667\n",
      "6  GKPPGFSPFRID          1    0.916667\n",
      "7  GLPPGFSPFRID          1    0.916667\n",
      "8  GRCPGFSPFRID          1    0.916667\n",
      "9  GRGPGFSPFRID          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CPNQPSDNMIRF          1    0.916667\n",
      "1  GPNQPSDNMIRF          1    0.916667\n",
      "2  RPNQPSDNMIRF          1    0.916667\n",
      "3  LPNQPSDNMIRF          1    0.916667\n",
      "4  ACNQPSDNMIRF          1    0.916667\n",
      "5  ARNQPSDNMIRF          1    0.916667\n",
      "6  AKNQPSDNMIRF          1    0.916667\n",
      "7  ALNQPSDNMIRF          1    0.916667\n",
      "8  APCQPSDNMIRF          1    0.916667\n",
      "9  APGQPSDNMIRF          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CSTSECFWKYCV          1    0.916667\n",
      "1  GSTSECFWKYCV          1    0.916667\n",
      "2  RSTSECFWKYCV          1    0.916667\n",
      "3  LSTSECFWKYCV          1    0.916667\n",
      "4  GCTSECFWKYCV          1    0.916667\n",
      "5  GRTSECFWKYCV          1    0.916667\n",
      "6  GKTSECFWKYCV          1    0.916667\n",
      "7  GLTSECFWKYCV          1    0.916667\n",
      "8  GSCSECFWKYCV          1    0.916667\n",
      "9  GSGSECFWKYCV          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "        peptide  mutations  similarity\n",
      "0  CICTPIPFPMCY          1    0.916667\n",
      "1  GICTPIPFPMCY          1    0.916667\n",
      "2  RICTPIPFPMCY          1    0.916667\n",
      "3  LICTPIPFPMCY          1    0.916667\n",
      "4  RCCTPIPFPMCY          1    0.916667\n",
      "5  RRCTPIPFPMCY          1    0.916667\n",
      "6  RKCTPIPFPMCY          1    0.916667\n",
      "7  RLCTPIPFPMCY          1    0.916667\n",
      "8  RICTPIPFPMCY          1    0.916667\n",
      "9  RIGTPIPFPMCY          1    0.916667\n",
      "# Samples =  15184\n",
      "val_loader length: 15\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([848, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([848, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([848, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([848, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 848 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([848, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([848, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([848, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGGLPRPGPEIPP          1    0.923077\n",
      "1  GGGLPRPGPEIPP          1    0.923077\n",
      "2  RGGLPRPGPEIPP          1    0.923077\n",
      "3  LGGLPRPGPEIPP          1    0.923077\n",
      "4  QCGLPRPGPEIPP          1    0.923077\n",
      "5  QRGLPRPGPEIPP          1    0.923077\n",
      "6  QKGLPRPGPEIPP          1    0.923077\n",
      "7  QLGLPRPGPEIPP          1    0.923077\n",
      "8  QGCLPRPGPEIPP          1    0.923077\n",
      "9  QGGLPRPGPEIPP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CSHISKARRPYIL          1    0.923077\n",
      "1  GSHISKARRPYIL          1    0.923077\n",
      "2  RSHISKARRPYIL          1    0.923077\n",
      "3  LSHISKARRPYIL          1    0.923077\n",
      "4  QCHISKARRPYIL          1    0.923077\n",
      "5  QRHISKARRPYIL          1    0.923077\n",
      "6  QKHISKARRPYIL          1    0.923077\n",
      "7  QLHISKARRPYIL          1    0.923077\n",
      "8  QSCISKARRPYIL          1    0.923077\n",
      "9  QSGISKARRPYIL          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CDKPFWSPPIYPH          1    0.923077\n",
      "1  GDKPFWSPPIYPH          1    0.923077\n",
      "2  RDKPFWSPPIYPH          1    0.923077\n",
      "3  LDKPFWSPPIYPH          1    0.923077\n",
      "4  QCKPFWSPPIYPH          1    0.923077\n",
      "5  QRKPFWSPPIYPH          1    0.923077\n",
      "6  QKKPFWSPPIYPH          1    0.923077\n",
      "7  QLKPFWSPPIYPH          1    0.923077\n",
      "8  QDCPFWSPPIYPH          1    0.923077\n",
      "9  QDGPFWSPPIYPH          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "617 QDKPFWSPPIYPH already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CFDEIDRSGFGFN          1    0.923077\n",
      "1  GFDEIDRSGFGFN          1    0.923077\n",
      "2  RFDEIDRSGFGFN          1    0.923077\n",
      "3  LFDEIDRSGFGFN          1    0.923077\n",
      "4  NCDEIDRSGFGFN          1    0.923077\n",
      "5  NRDEIDRSGFGFN          1    0.923077\n",
      "6  NKDEIDRSGFGFN          1    0.923077\n",
      "7  NLDEIDRSGFGFN          1    0.923077\n",
      "8  NFCEIDRSGFGFN          1    0.923077\n",
      "9  NFGEIDRSGFGFN          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGGGPQWAVGHFM          1    0.923077\n",
      "1  GGGGPQWAVGHFM          1    0.923077\n",
      "2  RGGGPQWAVGHFM          1    0.923077\n",
      "3  LGGGPQWAVGHFM          1    0.923077\n",
      "4  QCGGPQWAVGHFM          1    0.923077\n",
      "5  QRGGPQWAVGHFM          1    0.923077\n",
      "6  QKGGPQWAVGHFM          1    0.923077\n",
      "7  QLGGPQWAVGHFM          1    0.923077\n",
      "8  QGCGPQWAVGHFM          1    0.923077\n",
      "9  QGGGPQWAVGHFM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKFLCWQKSIHGS          1    0.923077\n",
      "1  GKFLCWQKSIHGS          1    0.923077\n",
      "2  RKFLCWQKSIHGS          1    0.923077\n",
      "3  LKFLCWQKSIHGS          1    0.923077\n",
      "4  MCFLCWQKSIHGS          1    0.923077\n",
      "5  MRFLCWQKSIHGS          1    0.923077\n",
      "6  MKFLCWQKSIHGS          1    0.923077\n",
      "7  MLFLCWQKSIHGS          1    0.923077\n",
      "8  MKCLCWQKSIHGS          1    0.923077\n",
      "9  MKGLCWQKSIHGS          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CDKPFWPPPIYPM          1    0.923077\n",
      "1  GDKPFWPPPIYPM          1    0.923077\n",
      "2  RDKPFWPPPIYPM          1    0.923077\n",
      "3  LDKPFWPPPIYPM          1    0.923077\n",
      "4  QCKPFWPPPIYPM          1    0.923077\n",
      "5  QRKPFWPPPIYPM          1    0.923077\n",
      "6  QKKPFWPPPIYPM          1    0.923077\n",
      "7  QLKPFWPPPIYPM          1    0.923077\n",
      "8  QDCPFWPPPIYPM          1    0.923077\n",
      "9  QDGPFWPPPIYPM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "622 QDKPFWPPPIYPM already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CCCHPACGKNFDC          1    0.923077\n",
      "1  GCCHPACGKNFDC          1    0.923077\n",
      "2  RCCHPACGKNFDC          1    0.923077\n",
      "3  LCCHPACGKNFDC          1    0.923077\n",
      "4  YCCHPACGKNFDC          1    0.923077\n",
      "5  YRCHPACGKNFDC          1    0.923077\n",
      "6  YKCHPACGKNFDC          1    0.923077\n",
      "7  YLCHPACGKNFDC          1    0.923077\n",
      "8  YCCHPACGKNFDC          1    0.923077\n",
      "9  YCGHPACGKNFDC          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CDKPFWDPPIYPV          1    0.923077\n",
      "1  GDKPFWDPPIYPV          1    0.923077\n",
      "2  RDKPFWDPPIYPV          1    0.923077\n",
      "3  LDKPFWDPPIYPV          1    0.923077\n",
      "4  QCKPFWDPPIYPV          1    0.923077\n",
      "5  QRKPFWDPPIYPV          1    0.923077\n",
      "6  QKKPFWDPPIYPV          1    0.923077\n",
      "7  QLKPFWDPPIYPV          1    0.923077\n",
      "8  QDCPFWDPPIYPV          1    0.923077\n",
      "9  QDGPFWDPPIYPV          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "625 QDKPFWDPPIYPV already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CYDRISGSAFSDF          1    0.923077\n",
      "1  GYDRISGSAFSDF          1    0.923077\n",
      "2  RYDRISGSAFSDF          1    0.923077\n",
      "3  LYDRISGSAFSDF          1    0.923077\n",
      "4  PCDRISGSAFSDF          1    0.923077\n",
      "5  PRDRISGSAFSDF          1    0.923077\n",
      "6  PKDRISGSAFSDF          1    0.923077\n",
      "7  PLDRISGSAFSDF          1    0.923077\n",
      "8  PYCRISGSAFSDF          1    0.923077\n",
      "9  PYGRISGSAFSDF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKKDKKDKFYGLM          1    0.923077\n",
      "1  GKKDKKDKFYGLM          1    0.923077\n",
      "2  RKKDKKDKFYGLM          1    0.923077\n",
      "3  LKKDKKDKFYGLM          1    0.923077\n",
      "4  QCKDKKDKFYGLM          1    0.923077\n",
      "5  QRKDKKDKFYGLM          1    0.923077\n",
      "6  QKKDKKDKFYGLM          1    0.923077\n",
      "7  QLKDKKDKFYGLM          1    0.923077\n",
      "8  QKCDKKDKFYGLM          1    0.923077\n",
      "9  QKGDKKDKFYGLM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKLLCWQKSIHGS          1    0.923077\n",
      "1  GKLLCWQKSIHGS          1    0.923077\n",
      "2  RKLLCWQKSIHGS          1    0.923077\n",
      "3  LKLLCWQKSIHGS          1    0.923077\n",
      "4  MCLLCWQKSIHGS          1    0.923077\n",
      "5  MRLLCWQKSIHGS          1    0.923077\n",
      "6  MKLLCWQKSIHGS          1    0.923077\n",
      "7  MLLLCWQKSIHGS          1    0.923077\n",
      "8  MKCLCWQKSIHGS          1    0.923077\n",
      "9  MKGLCWQKSIHGS          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGGWPRPGPEIPP          1    0.923077\n",
      "1  GGGWPRPGPEIPP          1    0.923077\n",
      "2  RGGWPRPGPEIPP          1    0.923077\n",
      "3  LGGWPRPGPEIPP          1    0.923077\n",
      "4  QCGWPRPGPEIPP          1    0.923077\n",
      "5  QRGWPRPGPEIPP          1    0.923077\n",
      "6  QKGWPRPGPEIPP          1    0.923077\n",
      "7  QLGWPRPGPEIPP          1    0.923077\n",
      "8  QGCWPRPGPEIPP          1    0.923077\n",
      "9  QGGWPRPGPEIPP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CAQEKRQPWLPFV          1    0.923077\n",
      "1  GAQEKRQPWLPFV          1    0.923077\n",
      "2  RAQEKRQPWLPFV          1    0.923077\n",
      "3  LAQEKRQPWLPFV          1    0.923077\n",
      "4  DCQEKRQPWLPFV          1    0.923077\n",
      "5  DRQEKRQPWLPFV          1    0.923077\n",
      "6  DKQEKRQPWLPFV          1    0.923077\n",
      "7  DLQEKRQPWLPFV          1    0.923077\n",
      "8  DACEKRQPWLPFV          1    0.923077\n",
      "9  DAGEKRQPWLPFV          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "631 DAQEKRQPWLPFV already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CFDRISNSAFSDF          1    0.923077\n",
      "1  GFDRISNSAFSDF          1    0.923077\n",
      "2  RFDRISNSAFSDF          1    0.923077\n",
      "3  LFDRISNSAFSDF          1    0.923077\n",
      "4  PCDRISNSAFSDF          1    0.923077\n",
      "5  PRDRISNSAFSDF          1    0.923077\n",
      "6  PKDRISNSAFSDF          1    0.923077\n",
      "7  PLDRISNSAFSDF          1    0.923077\n",
      "8  PFCRISNSAFSDF          1    0.923077\n",
      "9  PFGRISNSAFSDF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CEEEKVKWEPDVP          1    0.923077\n",
      "1  GEEEKVKWEPDVP          1    0.923077\n",
      "2  REEEKVKWEPDVP          1    0.923077\n",
      "3  LEEEKVKWEPDVP          1    0.923077\n",
      "4  NCEEKVKWEPDVP          1    0.923077\n",
      "5  NREEKVKWEPDVP          1    0.923077\n",
      "6  NKEEKVKWEPDVP          1    0.923077\n",
      "7  NLEEKVKWEPDVP          1    0.923077\n",
      "8  NECEKVKWEPDVP          1    0.923077\n",
      "9  NEGEKVKWEPDVP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "634 NEEEKVKWEPDVP already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CGRPPHPPIPPAP          1    0.923077\n",
      "1  GGRPPHPPIPPAP          1    0.923077\n",
      "2  RGRPPHPPIPPAP          1    0.923077\n",
      "3  LGRPPHPPIPPAP          1    0.923077\n",
      "4  QCRPPHPPIPPAP          1    0.923077\n",
      "5  QRRPPHPPIPPAP          1    0.923077\n",
      "6  QKRPPHPPIPPAP          1    0.923077\n",
      "7  QLRPPHPPIPPAP          1    0.923077\n",
      "8  QGCPPHPPIPPAP          1    0.923077\n",
      "9  QGGPPHPPIPPAP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CIYRELNRALAIL          1    0.923077\n",
      "1  GIYRELNRALAIL          1    0.923077\n",
      "2  RIYRELNRALAIL          1    0.923077\n",
      "3  LIYRELNRALAIL          1    0.923077\n",
      "4  MCYRELNRALAIL          1    0.923077\n",
      "5  MRYRELNRALAIL          1    0.923077\n",
      "6  MKYRELNRALAIL          1    0.923077\n",
      "7  MLYRELNRALAIL          1    0.923077\n",
      "8  MICRELNRALAIL          1    0.923077\n",
      "9  MIGRELNRALAIL          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CDKPFWSPPIYPV          1    0.923077\n",
      "1  GDKPFWSPPIYPV          1    0.923077\n",
      "2  RDKPFWSPPIYPV          1    0.923077\n",
      "3  LDKPFWSPPIYPV          1    0.923077\n",
      "4  QCKPFWSPPIYPV          1    0.923077\n",
      "5  QRKPFWSPPIYPV          1    0.923077\n",
      "6  QKKPFWSPPIYPV          1    0.923077\n",
      "7  QLKPFWSPPIYPV          1    0.923077\n",
      "8  QDCPFWSPPIYPV          1    0.923077\n",
      "9  QDGPFWSPPIYPV          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "638 QDKPFWSPPIYPV already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CAQEKRQPWIPFV          1    0.923077\n",
      "1  GAQEKRQPWIPFV          1    0.923077\n",
      "2  RAQEKRQPWIPFV          1    0.923077\n",
      "3  LAQEKRQPWIPFV          1    0.923077\n",
      "4  DCQEKRQPWIPFV          1    0.923077\n",
      "5  DRQEKRQPWIPFV          1    0.923077\n",
      "6  DKQEKRQPWIPFV          1    0.923077\n",
      "7  DLQEKRQPWIPFV          1    0.923077\n",
      "8  DACEKRQPWIPFV          1    0.923077\n",
      "9  DAGEKRQPWIPFV          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "640 DAQEKRQPWIPFV already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CYCCRRPTCIPIC          1    0.923077\n",
      "1  GYCCRRPTCIPIC          1    0.923077\n",
      "2  RYCCRRPTCIPIC          1    0.923077\n",
      "3  LYCCRRPTCIPIC          1    0.923077\n",
      "4  DCCCRRPTCIPIC          1    0.923077\n",
      "5  DRCCRRPTCIPIC          1    0.923077\n",
      "6  DKCCRRPTCIPIC          1    0.923077\n",
      "7  DLCCRRPTCIPIC          1    0.923077\n",
      "8  DYCCRRPTCIPIC          1    0.923077\n",
      "9  DYGCRRPTCIPIC          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CCCWPGRPDCCAP          1    0.923077\n",
      "1  GCCWPGRPDCCAP          1    0.923077\n",
      "2  RCCWPGRPDCCAP          1    0.923077\n",
      "3  LCCWPGRPDCCAP          1    0.923077\n",
      "4  DCCWPGRPDCCAP          1    0.923077\n",
      "5  DRCWPGRPDCCAP          1    0.923077\n",
      "6  DKCWPGRPDCCAP          1    0.923077\n",
      "7  DLCWPGRPDCCAP          1    0.923077\n",
      "8  DCCWPGRPDCCAP          1    0.923077\n",
      "9  DCGWPGRPDCCAP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CNREEMHCDVVKI          1    0.923077\n",
      "1  GNREEMHCDVVKI          1    0.923077\n",
      "2  RNREEMHCDVVKI          1    0.923077\n",
      "3  LNREEMHCDVVKI          1    0.923077\n",
      "4  MCREEMHCDVVKI          1    0.923077\n",
      "5  MRREEMHCDVVKI          1    0.923077\n",
      "6  MKREEMHCDVVKI          1    0.923077\n",
      "7  MLREEMHCDVVKI          1    0.923077\n",
      "8  MNCEEMHCDVVKI          1    0.923077\n",
      "9  MNGEEMHCDVVKI          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKKDKKDKFYGLF          1    0.923077\n",
      "1  GKKDKKDKFYGLF          1    0.923077\n",
      "2  RKKDKKDKFYGLF          1    0.923077\n",
      "3  LKKDKKDKFYGLF          1    0.923077\n",
      "4  QCKDKKDKFYGLF          1    0.923077\n",
      "5  QRKDKKDKFYGLF          1    0.923077\n",
      "6  QKKDKKDKFYGLF          1    0.923077\n",
      "7  QLKDKKDKFYGLF          1    0.923077\n",
      "8  QKCDKKDKFYGLF          1    0.923077\n",
      "9  QKGDKKDKFYGLF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGRAPHPPIPPAP          1    0.923077\n",
      "1  GGRAPHPPIPPAP          1    0.923077\n",
      "2  RGRAPHPPIPPAP          1    0.923077\n",
      "3  LGRAPHPPIPPAP          1    0.923077\n",
      "4  QCRAPHPPIPPAP          1    0.923077\n",
      "5  QRRAPHPPIPPAP          1    0.923077\n",
      "6  QKRAPHPPIPPAP          1    0.923077\n",
      "7  QLRAPHPPIPPAP          1    0.923077\n",
      "8  QGCAPHPPIPPAP          1    0.923077\n",
      "9  QGGAPHPPIPPAP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CFDRISSSAFSDF          1    0.923077\n",
      "1  GFDRISSSAFSDF          1    0.923077\n",
      "2  RFDRISSSAFSDF          1    0.923077\n",
      "3  LFDRISSSAFSDF          1    0.923077\n",
      "4  PCDRISSSAFSDF          1    0.923077\n",
      "5  PRDRISSSAFSDF          1    0.923077\n",
      "6  PKDRISSSAFSDF          1    0.923077\n",
      "7  PLDRISSSAFSDF          1    0.923077\n",
      "8  PFCRISSSAFSDF          1    0.923077\n",
      "9  PFGRISSSAFSDF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKDSMLLLQVPVY          1    0.923077\n",
      "1  GKDSMLLLQVPVY          1    0.923077\n",
      "2  RKDSMLLLQVPVY          1    0.923077\n",
      "3  LKDSMLLLQVPVY          1    0.923077\n",
      "4  PCDSMLLLQVPVY          1    0.923077\n",
      "5  PRDSMLLLQVPVY          1    0.923077\n",
      "6  PKDSMLLLQVPVY          1    0.923077\n",
      "7  PLDSMLLLQVPVY          1    0.923077\n",
      "8  PKCSMLLLQVPVY          1    0.923077\n",
      "9  PKGSMLLLQVPVY          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CDKPFWPPPIYIM          1    0.923077\n",
      "1  GDKPFWPPPIYIM          1    0.923077\n",
      "2  RDKPFWPPPIYIM          1    0.923077\n",
      "3  LDKPFWPPPIYIM          1    0.923077\n",
      "4  QCKPFWPPPIYIM          1    0.923077\n",
      "5  QRKPFWPPPIYIM          1    0.923077\n",
      "6  QKKPFWPPPIYIM          1    0.923077\n",
      "7  QLKPFWPPPIYIM          1    0.923077\n",
      "8  QDCPFWPPPIYIM          1    0.923077\n",
      "9  QDGPFWPPPIYIM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "649 QDKPFWPPPIYIM already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CELPQGLWVRPRL          1    0.923077\n",
      "1  GELPQGLWVRPRL          1    0.923077\n",
      "2  RELPQGLWVRPRL          1    0.923077\n",
      "3  LELPQGLWVRPRL          1    0.923077\n",
      "4  ACLPQGLWVRPRL          1    0.923077\n",
      "5  ARLPQGLWVRPRL          1    0.923077\n",
      "6  AKLPQGLWVRPRL          1    0.923077\n",
      "7  ALLPQGLWVRPRL          1    0.923077\n",
      "8  AECPQGLWVRPRL          1    0.923077\n",
      "9  AEGPQGLWVRPRL          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGVCCGYKLCHPC          1    0.923077\n",
      "1  GGVCCGYKLCHPC          1    0.923077\n",
      "2  RGVCCGYKLCHPC          1    0.923077\n",
      "3  LGVCCGYKLCHPC          1    0.923077\n",
      "4  VCVCCGYKLCHPC          1    0.923077\n",
      "5  VRVCCGYKLCHPC          1    0.923077\n",
      "6  VKVCCGYKLCHPC          1    0.923077\n",
      "7  VLVCCGYKLCHPC          1    0.923077\n",
      "8  VGCCCGYKLCHPC          1    0.923077\n",
      "9  VGGCCGYKLCHPC          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CAQEKRQPWLPFG          1    0.923077\n",
      "1  GAQEKRQPWLPFG          1    0.923077\n",
      "2  RAQEKRQPWLPFG          1    0.923077\n",
      "3  LAQEKRQPWLPFG          1    0.923077\n",
      "4  DCQEKRQPWLPFG          1    0.923077\n",
      "5  DRQEKRQPWLPFG          1    0.923077\n",
      "6  DKQEKRQPWLPFG          1    0.923077\n",
      "7  DLQEKRQPWLPFG          1    0.923077\n",
      "8  DACEKRQPWLPFG          1    0.923077\n",
      "9  DAGEKRQPWLPFG          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKKDKKDRFYGLM          1    0.923077\n",
      "1  GKKDKKDRFYGLM          1    0.923077\n",
      "2  RKKDKKDRFYGLM          1    0.923077\n",
      "3  LKKDKKDRFYGLM          1    0.923077\n",
      "4  QCKDKKDRFYGLM          1    0.923077\n",
      "5  QRKDKKDRFYGLM          1    0.923077\n",
      "6  QKKDKKDRFYGLM          1    0.923077\n",
      "7  QLKDKKDRFYGLM          1    0.923077\n",
      "8  QKCDKKDRFYGLM          1    0.923077\n",
      "9  QKGDKKDRFYGLM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CYDRISNSAFSDF          1    0.923077\n",
      "1  GYDRISNSAFSDF          1    0.923077\n",
      "2  RYDRISNSAFSDF          1    0.923077\n",
      "3  LYDRISNSAFSDF          1    0.923077\n",
      "4  PCDRISNSAFSDF          1    0.923077\n",
      "5  PRDRISNSAFSDF          1    0.923077\n",
      "6  PKDRISNSAFSDF          1    0.923077\n",
      "7  PLDRISNSAFSDF          1    0.923077\n",
      "8  PYCRISNSAFSDF          1    0.923077\n",
      "9  PYGRISNSAFSDF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CEKPYWPPPIYPM          1    0.923077\n",
      "1  GEKPYWPPPIYPM          1    0.923077\n",
      "2  REKPYWPPPIYPM          1    0.923077\n",
      "3  LEKPYWPPPIYPM          1    0.923077\n",
      "4  QCKPYWPPPIYPM          1    0.923077\n",
      "5  QRKPYWPPPIYPM          1    0.923077\n",
      "6  QKKPYWPPPIYPM          1    0.923077\n",
      "7  QLKPYWPPPIYPM          1    0.923077\n",
      "8  QECPYWPPPIYPM          1    0.923077\n",
      "9  QEGPYWPPPIYPM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "656 QEKPYWPPPIYPM already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CEEEKVKWQPDVP          1    0.923077\n",
      "1  GEEEKVKWQPDVP          1    0.923077\n",
      "2  REEEKVKWQPDVP          1    0.923077\n",
      "3  LEEEKVKWQPDVP          1    0.923077\n",
      "4  NCEEKVKWQPDVP          1    0.923077\n",
      "5  NREEKVKWQPDVP          1    0.923077\n",
      "6  NKEEKVKWQPDVP          1    0.923077\n",
      "7  NLEEKVKWQPDVP          1    0.923077\n",
      "8  NECEKVKWQPDVP          1    0.923077\n",
      "9  NEGEKVKWQPDVP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "658 NEEEKVKWQPDVP already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CLLDMVTGLLGNL          1    0.923077\n",
      "1  GLLDMVTGLLGNL          1    0.923077\n",
      "2  RLLDMVTGLLGNL          1    0.923077\n",
      "3  LLLDMVTGLLGNL          1    0.923077\n",
      "4  GCLDMVTGLLGNL          1    0.923077\n",
      "5  GRLDMVTGLLGNL          1    0.923077\n",
      "6  GKLDMVTGLLGNL          1    0.923077\n",
      "7  GLLDMVTGLLGNL          1    0.923077\n",
      "8  GLCDMVTGLLGNL          1    0.923077\n",
      "9  GLGDMVTGLLGNL          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CEEEKRQPWLPFG          1    0.923077\n",
      "1  GEEEKRQPWLPFG          1    0.923077\n",
      "2  REEEKRQPWLPFG          1    0.923077\n",
      "3  LEEEKRQPWLPFG          1    0.923077\n",
      "4  SCEEKRQPWLPFG          1    0.923077\n",
      "5  SREEKRQPWLPFG          1    0.923077\n",
      "6  SKEEKRQPWLPFG          1    0.923077\n",
      "7  SLEEKRQPWLPFG          1    0.923077\n",
      "8  SECEKRQPWLPFG          1    0.923077\n",
      "9  SEGEKRQPWLPFG          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "661 SEEEKRQPWLPFG already exists\n",
      "         peptide  mutations  similarity\n",
      "0  CHGGSWYRFPWGY          1    0.923077\n",
      "1  GHGGSWYRFPWGY          1    0.923077\n",
      "2  RHGGSWYRFPWGY          1    0.923077\n",
      "3  LHGGSWYRFPWGY          1    0.923077\n",
      "4  FCGGSWYRFPWGY          1    0.923077\n",
      "5  FRGGSWYRFPWGY          1    0.923077\n",
      "6  FKGGSWYRFPWGY          1    0.923077\n",
      "7  FLGGSWYRFPWGY          1    0.923077\n",
      "8  FHCGSWYRFPWGY          1    0.923077\n",
      "9  FHGGSWYRFPWGY          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGGTSGLYAFPRV          1    0.923077\n",
      "1  GGGTSGLYAFPRV          1    0.923077\n",
      "2  RGGTSGLYAFPRV          1    0.923077\n",
      "3  LGGTSGLYAFPRV          1    0.923077\n",
      "4  ACGTSGLYAFPRV          1    0.923077\n",
      "5  ARGTSGLYAFPRV          1    0.923077\n",
      "6  AKGTSGLYAFPRV          1    0.923077\n",
      "7  ALGTSGLYAFPRV          1    0.923077\n",
      "8  AGCTSGLYAFPRV          1    0.923077\n",
      "9  AGGTSGLYAFPRV          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CYAMEHFRWGKPV          1    0.923077\n",
      "1  GYAMEHFRWGKPV          1    0.923077\n",
      "2  RYAMEHFRWGKPV          1    0.923077\n",
      "3  LYAMEHFRWGKPV          1    0.923077\n",
      "4  SCAMEHFRWGKPV          1    0.923077\n",
      "5  SRAMEHFRWGKPV          1    0.923077\n",
      "6  SKAMEHFRWGKPV          1    0.923077\n",
      "7  SLAMEHFRWGKPV          1    0.923077\n",
      "8  SYCMEHFRWGKPV          1    0.923077\n",
      "9  SYGMEHFRWGKPV          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CARPPHPPIPPAP          1    0.923077\n",
      "1  GARPPHPPIPPAP          1    0.923077\n",
      "2  RARPPHPPIPPAP          1    0.923077\n",
      "3  LARPPHPPIPPAP          1    0.923077\n",
      "4  QCRPPHPPIPPAP          1    0.923077\n",
      "5  QRRPPHPPIPPAP          1    0.923077\n",
      "6  QKRPPHPPIPPAP          1    0.923077\n",
      "7  QLRPPHPPIPPAP          1    0.923077\n",
      "8  QACPPHPPIPPAP          1    0.923077\n",
      "9  QAGPPHPPIPPAP          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CCCMRPICMCPCC          1    0.923077\n",
      "1  GCCMRPICMCPCC          1    0.923077\n",
      "2  RCCMRPICMCPCC          1    0.923077\n",
      "3  LCCMRPICMCPCC          1    0.923077\n",
      "4  KCCMRPICMCPCC          1    0.923077\n",
      "5  KRCMRPICMCPCC          1    0.923077\n",
      "6  KKCMRPICMCPCC          1    0.923077\n",
      "7  KLCMRPICMCPCC          1    0.923077\n",
      "8  KCCMRPICMCPCC          1    0.923077\n",
      "9  KCGMRPICMCPCC          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKNDKKDRFYGLM          1    0.923077\n",
      "1  GKNDKKDRFYGLM          1    0.923077\n",
      "2  RKNDKKDRFYGLM          1    0.923077\n",
      "3  LKNDKKDRFYGLM          1    0.923077\n",
      "4  QCNDKKDRFYGLM          1    0.923077\n",
      "5  QRNDKKDRFYGLM          1    0.923077\n",
      "6  QKNDKKDRFYGLM          1    0.923077\n",
      "7  QLNDKKDRFYGLM          1    0.923077\n",
      "8  QKCDKKDRFYGLM          1    0.923077\n",
      "9  QKGDKKDRFYGLM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CKKDKKDRFYGLF          1    0.923077\n",
      "1  GKKDKKDRFYGLF          1    0.923077\n",
      "2  RKKDKKDRFYGLF          1    0.923077\n",
      "3  LKKDKKDRFYGLF          1    0.923077\n",
      "4  QCKDKKDRFYGLF          1    0.923077\n",
      "5  QRKDKKDRFYGLF          1    0.923077\n",
      "6  QKKDKKDRFYGLF          1    0.923077\n",
      "7  QLKDKKDRFYGLF          1    0.923077\n",
      "8  QKCDKKDRFYGLF          1    0.923077\n",
      "9  QKGDKKDRFYGLF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CCCHPACGKHFSC          1    0.923077\n",
      "1  GCCHPACGKHFSC          1    0.923077\n",
      "2  RCCHPACGKHFSC          1    0.923077\n",
      "3  LCCHPACGKHFSC          1    0.923077\n",
      "4  ECCHPACGKHFSC          1    0.923077\n",
      "5  ERCHPACGKHFSC          1    0.923077\n",
      "6  EKCHPACGKHFSC          1    0.923077\n",
      "7  ELCHPACGKHFSC          1    0.923077\n",
      "8  ECCHPACGKHFSC          1    0.923077\n",
      "9  ECGHPACGKHFSC          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CVQLVDLARCVSF          1    0.923077\n",
      "1  GVQLVDLARCVSF          1    0.923077\n",
      "2  RVQLVDLARCVSF          1    0.923077\n",
      "3  LVQLVDLARCVSF          1    0.923077\n",
      "4  MCQLVDLARCVSF          1    0.923077\n",
      "5  MRQLVDLARCVSF          1    0.923077\n",
      "6  MKQLVDLARCVSF          1    0.923077\n",
      "7  MLQLVDLARCVSF          1    0.923077\n",
      "8  MVCLVDLARCVSF          1    0.923077\n",
      "9  MVGLVDLARCVSF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CCLEYGHSCWGAH          1    0.923077\n",
      "1  GCLEYGHSCWGAH          1    0.923077\n",
      "2  RCLEYGHSCWGAH          1    0.923077\n",
      "3  LCLEYGHSCWGAH          1    0.923077\n",
      "4  SCLEYGHSCWGAH          1    0.923077\n",
      "5  SRLEYGHSCWGAH          1    0.923077\n",
      "6  SKLEYGHSCWGAH          1    0.923077\n",
      "7  SLLEYGHSCWGAH          1    0.923077\n",
      "8  SCCEYGHSCWGAH          1    0.923077\n",
      "9  SCGEYGHSCWGAH          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CTRVQFKHHHHPD          1    0.923077\n",
      "1  GTRVQFKHHHHPD          1    0.923077\n",
      "2  RTRVQFKHHHHPD          1    0.923077\n",
      "3  LTRVQFKHHHHPD          1    0.923077\n",
      "4  MCRVQFKHHHHPD          1    0.923077\n",
      "5  MRRVQFKHHHHPD          1    0.923077\n",
      "6  MKRVQFKHHHHPD          1    0.923077\n",
      "7  MLRVQFKHHHHPD          1    0.923077\n",
      "8  MTCVQFKHHHHPD          1    0.923077\n",
      "9  MTGVQFKHHHHPD          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CCPAGCRSQGCCM          1    0.923077\n",
      "1  GCPAGCRSQGCCM          1    0.923077\n",
      "2  RCPAGCRSQGCCM          1    0.923077\n",
      "3  LCPAGCRSQGCCM          1    0.923077\n",
      "4  NCPAGCRSQGCCM          1    0.923077\n",
      "5  NRPAGCRSQGCCM          1    0.923077\n",
      "6  NKPAGCRSQGCCM          1    0.923077\n",
      "7  NLPAGCRSQGCCM          1    0.923077\n",
      "8  NCCAGCRSQGCCM          1    0.923077\n",
      "9  NCGAGCRSQGCCM          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CYCCRRPPCTLIC          1    0.923077\n",
      "1  GYCCRRPPCTLIC          1    0.923077\n",
      "2  RYCCRRPPCTLIC          1    0.923077\n",
      "3  LYCCRRPPCTLIC          1    0.923077\n",
      "4  DCCCRRPPCTLIC          1    0.923077\n",
      "5  DRCCRRPPCTLIC          1    0.923077\n",
      "6  DKCCRRPPCTLIC          1    0.923077\n",
      "7  DLCCRRPPCTLIC          1    0.923077\n",
      "8  DYCCRRPPCTLIC          1    0.923077\n",
      "9  DYGCRRPPCTLIC          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGGTSGLFAFPRV          1    0.923077\n",
      "1  GGGTSGLFAFPRV          1    0.923077\n",
      "2  RGGTSGLFAFPRV          1    0.923077\n",
      "3  LGGTSGLFAFPRV          1    0.923077\n",
      "4  NCGTSGLFAFPRV          1    0.923077\n",
      "5  NRGTSGLFAFPRV          1    0.923077\n",
      "6  NKGTSGLFAFPRV          1    0.923077\n",
      "7  NLGTSGLFAFPRV          1    0.923077\n",
      "8  NGCTSGLFAFPRV          1    0.923077\n",
      "9  NGGTSGLFAFPRV          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CDIGISEPNFLRF          1    0.923077\n",
      "1  GDIGISEPNFLRF          1    0.923077\n",
      "2  RDIGISEPNFLRF          1    0.923077\n",
      "3  LDIGISEPNFLRF          1    0.923077\n",
      "4  SCIGISEPNFLRF          1    0.923077\n",
      "5  SRIGISEPNFLRF          1    0.923077\n",
      "6  SKIGISEPNFLRF          1    0.923077\n",
      "7  SLIGISEPNFLRF          1    0.923077\n",
      "8  SDCGISEPNFLRF          1    0.923077\n",
      "9  SDGGISEPNFLRF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CAIVSKARRPYIL          1    0.923077\n",
      "1  GAIVSKARRPYIL          1    0.923077\n",
      "2  RAIVSKARRPYIL          1    0.923077\n",
      "3  LAIVSKARRPYIL          1    0.923077\n",
      "4  QCIVSKARRPYIL          1    0.923077\n",
      "5  QRIVSKARRPYIL          1    0.923077\n",
      "6  QKIVSKARRPYIL          1    0.923077\n",
      "7  QLIVSKARRPYIL          1    0.923077\n",
      "8  QACVSKARRPYIL          1    0.923077\n",
      "9  QAGVSKARRPYIL          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CAIDPNPDTPDSE          1    0.923077\n",
      "1  GAIDPNPDTPDSE          1    0.923077\n",
      "2  RAIDPNPDTPDSE          1    0.923077\n",
      "3  LAIDPNPDTPDSE          1    0.923077\n",
      "4  SCIDPNPDTPDSE          1    0.923077\n",
      "5  SRIDPNPDTPDSE          1    0.923077\n",
      "6  SKIDPNPDTPDSE          1    0.923077\n",
      "7  SLIDPNPDTPDSE          1    0.923077\n",
      "8  SACDPNPDTPDSE          1    0.923077\n",
      "9  SAGDPNPDTPDSE          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CYDRISSSAFSDF          1    0.923077\n",
      "1  GYDRISSSAFSDF          1    0.923077\n",
      "2  RYDRISSSAFSDF          1    0.923077\n",
      "3  LYDRISSSAFSDF          1    0.923077\n",
      "4  PCDRISSSAFSDF          1    0.923077\n",
      "5  PRDRISSSAFSDF          1    0.923077\n",
      "6  PKDRISSSAFSDF          1    0.923077\n",
      "7  PLDRISSSAFSDF          1    0.923077\n",
      "8  PYCRISSSAFSDF          1    0.923077\n",
      "9  PYGRISSSAFSDF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CDDGSYKPHIYGF          1    0.923077\n",
      "1  GDDGSYKPHIYGF          1    0.923077\n",
      "2  RDDGSYKPHIYGF          1    0.923077\n",
      "3  LDDGSYKPHIYGF          1    0.923077\n",
      "4  YCDGSYKPHIYGF          1    0.923077\n",
      "5  YRDGSYKPHIYGF          1    0.923077\n",
      "6  YKDGSYKPHIYGF          1    0.923077\n",
      "7  YLDGSYKPHIYGF          1    0.923077\n",
      "8  YDCGSYKPHIYGF          1    0.923077\n",
      "9  YDGGSYKPHIYGF          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "         peptide  mutations  similarity\n",
      "0  CGGGNRGDPSGVC          1    0.923077\n",
      "1  GGGGNRGDPSGVC          1    0.923077\n",
      "2  RGGGNRGDPSGVC          1    0.923077\n",
      "3  LGGGNRGDPSGVC          1    0.923077\n",
      "4  ECGGNRGDPSGVC          1    0.923077\n",
      "5  ERGGNRGDPSGVC          1    0.923077\n",
      "6  EKGGNRGDPSGVC          1    0.923077\n",
      "7  ELGGNRGDPSGVC          1    0.923077\n",
      "8  EGCGNRGDPSGVC          1    0.923077\n",
      "9  EGGGNRGDPSGVC          1    0.923077\n",
      "# Samples =  19604\n",
      "val_loader length: 20\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([148, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([148, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([148, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([148, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 148 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([148, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([148, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([148, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CKAIFVLKGWWRTS          1    0.928571\n",
      "1  GKAIFVLKGWWRTS          1    0.928571\n",
      "2  RKAIFVLKGWWRTS          1    0.928571\n",
      "3  LKAIFVLKGWWRTS          1    0.928571\n",
      "4  MCAIFVLKGWWRTS          1    0.928571\n",
      "5  MRAIFVLKGWWRTS          1    0.928571\n",
      "6  MKAIFVLKGWWRTS          1    0.928571\n",
      "7  MLAIFVLKGWWRTS          1    0.928571\n",
      "8  MKCIFVLKGWWRTS          1    0.928571\n",
      "9  MKGIFVLKGWWRTS          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CTHSMRLRFPTLNQ          1    0.928571\n",
      "1  GTHSMRLRFPTLNQ          1    0.928571\n",
      "2  RTHSMRLRFPTLNQ          1    0.928571\n",
      "3  LTHSMRLRFPTLNQ          1    0.928571\n",
      "4  MCHSMRLRFPTLNQ          1    0.928571\n",
      "5  MRHSMRLRFPTLNQ          1    0.928571\n",
      "6  MKHSMRLRFPTLNQ          1    0.928571\n",
      "7  MLHSMRLRFPTLNQ          1    0.928571\n",
      "8  MTCSMRLRFPTLNQ          1    0.928571\n",
      "9  MTGSMRLRFPTLNQ          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CCCSKLHDNSCCGL          1    0.928571\n",
      "1  GCCSKLHDNSCCGL          1    0.928571\n",
      "2  RCCSKLHDNSCCGL          1    0.928571\n",
      "3  LCCSKLHDNSCCGL          1    0.928571\n",
      "4  PCCSKLHDNSCCGL          1    0.928571\n",
      "5  PRCSKLHDNSCCGL          1    0.928571\n",
      "6  PKCSKLHDNSCCGL          1    0.928571\n",
      "7  PLCSKLHDNSCCGL          1    0.928571\n",
      "8  PCCSKLHDNSCCGL          1    0.928571\n",
      "9  PCGSKLHDNSCCGL          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CPCCSIHDNSCCGI          1    0.928571\n",
      "1  GPCCSIHDNSCCGI          1    0.928571\n",
      "2  RPCCSIHDNSCCGI          1    0.928571\n",
      "3  LPCCSIHDNSCCGI          1    0.928571\n",
      "4  KCCCSIHDNSCCGI          1    0.928571\n",
      "5  KRCCSIHDNSCCGI          1    0.928571\n",
      "6  KKCCSIHDNSCCGI          1    0.928571\n",
      "7  KLCCSIHDNSCCGI          1    0.928571\n",
      "8  KPCCSIHDNSCCGI          1    0.928571\n",
      "9  KPGCSIHDNSCCGI          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CAATFALHGWWRTS          1    0.928571\n",
      "1  GAATFALHGWWRTS          1    0.928571\n",
      "2  RAATFALHGWWRTS          1    0.928571\n",
      "3  LAATFALHGWWRTS          1    0.928571\n",
      "4  MCATFALHGWWRTS          1    0.928571\n",
      "5  MRATFALHGWWRTS          1    0.928571\n",
      "6  MKATFALHGWWRTS          1    0.928571\n",
      "7  MLATFALHGWWRTS          1    0.928571\n",
      "8  MACTFALHGWWRTS          1    0.928571\n",
      "9  MAGTFALHGWWRTS          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CNAAIFRFFFYFST          1    0.928571\n",
      "1  GNAAIFRFFFYFST          1    0.928571\n",
      "2  RNAAIFRFFFYFST          1    0.928571\n",
      "3  LNAAIFRFFFYFST          1    0.928571\n",
      "4  MCAAIFRFFFYFST          1    0.928571\n",
      "5  MRAAIFRFFFYFST          1    0.928571\n",
      "6  MKAAIFRFFFYFST          1    0.928571\n",
      "7  MLAAIFRFFFYFST          1    0.928571\n",
      "8  MNCAIFRFFFYFST          1    0.928571\n",
      "9  MNGAIFRFFFYFST          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CSIFRIHLDGNKKA          1    0.928571\n",
      "1  GSIFRIHLDGNKKA          1    0.928571\n",
      "2  RSIFRIHLDGNKKA          1    0.928571\n",
      "3  LSIFRIHLDGNKKA          1    0.928571\n",
      "4  MCIFRIHLDGNKKA          1    0.928571\n",
      "5  MRIFRIHLDGNKKA          1    0.928571\n",
      "6  MKIFRIHLDGNKKA          1    0.928571\n",
      "7  MLIFRIHLDGNKKA          1    0.928571\n",
      "8  MSCFRIHLDGNKKA          1    0.928571\n",
      "9  MSGFRIHLDGNKKA          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CPPTPPEHRFPGLM          1    0.928571\n",
      "1  GPPTPPEHRFPGLM          1    0.928571\n",
      "2  RPPTPPEHRFPGLM          1    0.928571\n",
      "3  LPPTPPEHRFPGLM          1    0.928571\n",
      "4  QCPTPPEHRFPGLM          1    0.928571\n",
      "5  QRPTPPEHRFPGLM          1    0.928571\n",
      "6  QKPTPPEHRFPGLM          1    0.928571\n",
      "7  QLPTPPEHRFPGLM          1    0.928571\n",
      "8  QPCTPPEHRFPGLM          1    0.928571\n",
      "9  QPGTPPEHRFPGLM          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CFSKLAQSSIKAMF          1    0.928571\n",
      "1  GFSKLAQSSIKAMF          1    0.928571\n",
      "2  RFSKLAQSSIKAMF          1    0.928571\n",
      "3  LFSKLAQSSIKAMF          1    0.928571\n",
      "4  MCSKLAQSSIKAMF          1    0.928571\n",
      "5  MRSKLAQSSIKAMF          1    0.928571\n",
      "6  MKSKLAQSSIKAMF          1    0.928571\n",
      "7  MLSKLAQSSIKAMF          1    0.928571\n",
      "8  MFCKLAQSSIKAMF          1    0.928571\n",
      "9  MFGKLAQSSIKAMF          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([1024, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([1024, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([1024, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 1024 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([1024, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([1024, 9, 50, 50])\n",
      "val_pep_inputs: torch.Size([232, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn_pad_mask shape: torch.Size([232, 50, 50])\n",
      "attn shape in scaled dot product attention: torch.Size([232, 9, 50, 50])\n",
      "attn shape in multi head attention: torch.Size([232, 9, 50, 50])\n",
      "dec_self_attn shape in decoder layer: 232 torch.Size([9, 50, 50])\n",
      "dec_self_attns shape in decoder: 1 torch.Size([232, 9, 50, 50])\n",
      "dec_self_attns shape in transformer: 1 torch.Size([232, 9, 50, 50])\n",
      "val_dec_self_attns shape: 1 torch.Size([232, 9, 50, 50])\n",
      "          peptide  mutations  similarity\n",
      "0  CDPEAPGIWFGPRL          1    0.928571\n",
      "1  GDPEAPGIWFGPRL          1    0.928571\n",
      "2  RDPEAPGIWFGPRL          1    0.928571\n",
      "3  LDPEAPGIWFGPRL          1    0.928571\n",
      "4  SCPEAPGIWFGPRL          1    0.928571\n",
      "5  SRPEAPGIWFGPRL          1    0.928571\n",
      "6  SKPEAPGIWFGPRL          1    0.928571\n",
      "7  SLPEAPGIWFGPRL          1    0.928571\n",
      "8  SDCEAPGIWFGPRL          1    0.928571\n",
      "9  SDGEAPGIWFGPRL          1    0.928571\n",
      "# Samples =  24808\n",
      "val_loader length: 25\n",
      "val_pep_inputs: torch.Size([1024, 50])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 125\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(mutated_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m    123\u001b[0m predict_data, predict_pep_inputs, predict_loader \u001b[38;5;241m=\u001b[39m read_predict_data(mutated_df, batch_size)\n\u001b[1;32m--> 125\u001b[0m y_pred, y_prob, attns \u001b[38;5;241m=\u001b[39m \u001b[43meval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m predict_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m], predict_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_prob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred, y_prob\n\u001b[0;32m    128\u001b[0m predict_data \u001b[38;5;241m=\u001b[39m predict_data\u001b[38;5;241m.\u001b[39mround({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_prob\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m})\n",
      "File \u001b[1;32md:\\Faks\\4. godina\\Evolucijsko računarstvo\\Projekt\\antimicrobial\\model.py:377\u001b[0m, in \u001b[0;36meval_step\u001b[1;34m(model, val_loader, threshold, use_cuda)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_pep_inputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_pep_inputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    376\u001b[0m val_pep_inputs \u001b[38;5;241m=\u001b[39m val_pep_inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 377\u001b[0m val_outputs, _, val_dec_self_attns \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_pep_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m y_prob_val \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSoftmax(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)(val_outputs)[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    380\u001b[0m y_prob_val_list\u001b[38;5;241m.\u001b[39mextend(y_prob_val)\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faks\\4. godina\\Evolucijsko računarstvo\\Projekt\\antimicrobial\\model.py:352\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, pep_inputs)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03mpep_inputs: [batch_size, pep_len]\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mhla_inputs: [batch_size, hla_len]\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# tensor to store decoder outputs\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m pep_enc_outputs, pep_enc_self_attns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpep_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpep_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# hla_enc_outputs, hla_enc_self_attns = self.hla_encoder(hla_inputs)\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# enc_outputs = torch.cat((pep_enc_outputs, hla_enc_outputs), 1) # concat pep & hla embedding\u001b[39;00m\n\u001b[0;32m    355\u001b[0m enc_outputs \u001b[38;5;241m=\u001b[39m pep_enc_outputs\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faks\\4. godina\\Evolucijsko računarstvo\\Projekt\\antimicrobial\\model.py:266\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, enc_inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m enc_self_attns \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# output n-tog layera je input n+1-og layera (zato layeru kao input dajemo enc_output) \u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     enc_outputs, enc_self_attn \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_self_attn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     enc_self_attns\u001b[38;5;241m.\u001b[39mappend(enc_self_attn)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# vraca se output samo od zadnjeg layera, i attention od svih layera\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faks\\4. godina\\Evolucijsko računarstvo\\Projekt\\antimicrobial\\model.py:244\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, enc_inputs, enc_self_attn_mask)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03menc_inputs: [batch_size, src_len, d_model]\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03menc_self_attn_mask: [batch_size, src_len, src_len]\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m enc_outputs, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_self_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_self_attn_mask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# enc_inputs to same Q,K,V\u001b[39;00m\n\u001b[0;32m    245\u001b[0m enc_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_ffn(enc_outputs) \u001b[38;5;66;03m# enc_outputs: [batch_size, src_len, d_model]\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enc_outputs, attn\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faks\\4. godina\\Evolucijsko računarstvo\\Projekt\\antimicrobial\\model.py:205\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, input_Q, input_K, input_V, attn_mask)\u001b[0m\n\u001b[0;32m    202\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, n_heads, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# attn_mask : [batch_size, n_heads, seq_len, seq_len]\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m context, attn \u001b[38;5;241m=\u001b[39m \u001b[43mScaledDotProductAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m context \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_heads \u001b[38;5;241m*\u001b[39m d_v) \u001b[38;5;66;03m# context: [batch_size, len_q, n_heads * d_v]\u001b[39;00m\n\u001b[0;32m    207\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(context) \u001b[38;5;66;03m# [batch_size, len_q, d_model]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LukaBursic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faks\\4. godina\\Evolucijsko računarstvo\\Projekt\\antimicrobial\\model.py:169\u001b[0m, in \u001b[0;36mScaledDotProductAttention.forward\u001b[1;34m(self, Q, K, V, attn_mask)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# matmul = matrix multiplication\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# transpose(-1,-2) - zamijeni zadnju i predzadnju dimenziju\u001b[39;00m\n\u001b[0;32m    168\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(Q, K\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(d_k) \u001b[38;5;66;03m# scores : [batch_size, n_heads, len_q, len_k]\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1e9\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Fills elements of self tensor with value where mask is True.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m attn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(scores)\n\u001b[0;32m    172\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn, V) \u001b[38;5;66;03m# [batch_size, n_heads, len_q, d_v]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Define the mutate_sequence function\n",
    "# def mutate_sequence(sequence):\n",
    "#     ls = []\n",
    "#     ls.append(sequence.replace('G', 'C'))\n",
    "#     ls.append(sequence.replace('G', 'L'))\n",
    "#     ls.append(sequence.replace('G', 'K'))\n",
    "#     return ls\n",
    "\n",
    "# def mutate_sequence(sequence):\n",
    "#     print('----------')\n",
    "#     top_aa = pd.read_csv('top_amino_acids.csv')\n",
    "#     # print(top_aa['Top 1'][0])\n",
    "#     ls = []\n",
    "    \n",
    "#     for i in range(len(sequence)):\n",
    "#         seq_list = list(sequence)  # Convert sequence to a list of characters\n",
    "#         seq_list[i] = top_aa['Top 1'][i]\n",
    "#         mutated_sequence = ''.join(seq_list)  # Join the list back into a string\n",
    "#         ls.append(mutated_sequence)\n",
    "\n",
    "#         seq_list = list(sequence)  # Convert sequence to a list of characters\n",
    "#         seq_list[i] = top_aa['Top 2'][i]\n",
    "#         mutated_sequence = ''.join(seq_list)  # Join the list back into a string\n",
    "#         ls.append(mutated_sequence)\n",
    "\n",
    "#         seq_list = list(sequence)  # Convert sequence to a list of characters\n",
    "#         seq_list[i] = top_aa['Top 3'][i]\n",
    "#         mutated_sequence = ''.join(seq_list)  # Join the list back into a string\n",
    "#         ls.append(mutated_sequence)\n",
    "\n",
    "#         seq_list = list(sequence)  # Convert sequence to a list of characters\n",
    "#         seq_list[i] = top_aa['Top 4'][i]\n",
    "#         mutated_sequence = ''.join(seq_list)  # Join the list back into a string\n",
    "#         ls.append(mutated_sequence)\n",
    "        \n",
    "#     return ls\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations, product\n",
    "\n",
    "# def mutate_sequence(sequence, max_mutations=4):\n",
    "#     top_aa = pd.read_csv('top_amino_acids.csv')\n",
    "#     ls = []\n",
    "    \n",
    "#     # Function to apply mutations to a sequence\n",
    "#     def apply_mutations(seq, mutations):\n",
    "#         seq_list = list(seq)\n",
    "#         for pos, top_idx in mutations:\n",
    "#             seq_list[pos] = top_aa.iloc[pos, top_idx]\n",
    "#         return ''.join(seq_list)\n",
    "\n",
    "#     print(\"max mut = \", max_mutations)\n",
    "#     # Generate mutations for 1 to max_mutations\n",
    "#     for num_mutations in range(1, max_mutations + 1):\n",
    "#         for positions in combinations(range(len(sequence)), num_mutations):\n",
    "#             # For each combination of positions, generate the possible mutations\n",
    "#             mutation_indices = [range(1, 5)] * num_mutations\n",
    "#             for mutation_combination in product(*mutation_indices):\n",
    "#                 mutations = list(zip(positions, mutation_combination))\n",
    "#                 mutated_sequence = apply_mutations(sequence, mutations)\n",
    "#                 ls.append(mutated_sequence)\n",
    "    \n",
    "#     return ls\n",
    "\n",
    "def mutate_sequence(sequence, max_mutations=4):\n",
    "    top_aa = pd.read_csv('top_amino_acids.csv')\n",
    "    mutated_sequences = []\n",
    "    \n",
    "    # Function to apply mutations to a sequence\n",
    "    def apply_mutations(seq, mutations):\n",
    "        seq_list = list(seq)\n",
    "        for pos, top_idx in mutations:\n",
    "            seq_list[pos] = top_aa.iloc[pos, top_idx]\n",
    "        return ''.join(seq_list)\n",
    "\n",
    "    # Generate mutations for 1 to max_mutations\n",
    "    for num_mutations in range(1, max_mutations + 1):\n",
    "        similarity = 1 - num_mutations/len(sequence)\n",
    "        for positions in combinations(range(len(sequence)), num_mutations):\n",
    "            # For each combination of positions, generate the possible mutations\n",
    "            mutation_indices = [range(1, 5)] * num_mutations\n",
    "            for mutation_combination in product(*mutation_indices):\n",
    "                mutations = list(zip(positions, mutation_combination))\n",
    "                mutated_sequence = apply_mutations(sequence, mutations)\n",
    "                mutated_sequences.append((mutated_sequence, num_mutations, similarity))\n",
    "    \n",
    "    return mutated_sequences\n",
    "\n",
    "# Read the original dataset\n",
    "data = pd.read_csv('./true_negative_samples.csv')\n",
    "\n",
    "# Create a list to store the new sequences and their labels\n",
    "\n",
    "\n",
    "model_eval.eval()\n",
    "# Iterate over the original sequences and generate mutations\n",
    "for i in range(len(data)):\n",
    "    mutated_data = []\n",
    "    original_sequence = data['sequence'][i]\n",
    "\n",
    "    if os.path.isfile(f'mutated_datasets_new/mutated_dataset_{original_sequence}_new.csv'):\n",
    "        print(i, original_sequence, \"already exists\")\n",
    "        continue\n",
    "\n",
    "    original_label = data['label'][i]\n",
    "    mutations = mutate_sequence(original_sequence, max_mutations=math.ceil(0.2*len(original_sequence)))\n",
    "    \n",
    "    # Add the original sequence to the new dataset\n",
    "    # mutated_data.append({'sequence': original_sequence, 'label': original_label})\n",
    "    \n",
    "    # Add the mutated sequences to the new dataset\n",
    "    for mutated_sequence, num_mutations, similarity in mutations:\n",
    "        mutated_data.append({'peptide': mutated_sequence, 'mutations': num_mutations, 'similarity': similarity})\n",
    "\n",
    "    # Create a new DataFrame from the mutated_data list\n",
    "    mutated_df = pd.DataFrame(mutated_data)\n",
    "\n",
    "    # Display the new DataFrame\n",
    "    print(mutated_df.head(10))\n",
    "\n",
    "    predict_data, predict_pep_inputs, predict_loader = read_predict_data(mutated_df, batch_size)\n",
    "    \n",
    "    y_pred, y_prob, attns = eval_step(model_eval, predict_loader, 0.5, use_cuda)\n",
    "\n",
    "    predict_data['y_pred'], predict_data['y_prob'] = y_pred, y_prob\n",
    "    predict_data = predict_data.round({'y_prob': 4})\n",
    "\n",
    "    predict_data.to_csv(f'mutated_datasets_new/mutated_dataset_{original_sequence}_new.csv', index = False)\n",
    "\n",
    "    # Optionally, save the new DataFrame to a CSV file\n",
    "    # mutated_df.to_csv(f'mutated_datasets/mutated_dataset_{original_sequence}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CEP', 1, 0.6666666666666667), ('GEP', 1, 0.6666666666666667), ('REP', 1, 0.6666666666666667), ('LEP', 1, 0.6666666666666667), ('GCP', 1, 0.6666666666666667), ('GRP', 1, 0.6666666666666667), ('GKP', 1, 0.6666666666666667), ('GLP', 1, 0.6666666666666667), ('GEC', 1, 0.6666666666666667), ('GEG', 1, 0.6666666666666667), ('GEL', 1, 0.6666666666666667), ('GEV', 1, 0.6666666666666667)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutated Sequence</th>\n",
       "      <th>Number of Mutations</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GKP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GLP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GEG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GEV</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mutated Sequence  Number of Mutations  Similarity\n",
       "0               CEP                    1    0.666667\n",
       "1               GEP                    1    0.666667\n",
       "2               REP                    1    0.666667\n",
       "3               LEP                    1    0.666667\n",
       "4               GCP                    1    0.666667\n",
       "5               GRP                    1    0.666667\n",
       "6               GKP                    1    0.666667\n",
       "7               GLP                    1    0.666667\n",
       "8               GEC                    1    0.666667\n",
       "9               GEG                    1    0.666667\n",
       "10              GEL                    1    0.666667\n",
       "11              GEV                    1    0.666667"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations, product\n",
    "\n",
    "def mutate_sequence(sequence, max_mutations=4):\n",
    "    top_aa = pd.read_csv('top_amino_acids.csv')\n",
    "    mutated_sequences = []\n",
    "    \n",
    "    # Function to apply mutations to a sequence\n",
    "    def apply_mutations(seq, mutations):\n",
    "        seq_list = list(seq)\n",
    "        for pos, top_idx in mutations:\n",
    "            seq_list[pos] = top_aa.iloc[pos, top_idx]\n",
    "        return ''.join(seq_list)\n",
    "\n",
    "    # Generate mutations for 1 to max_mutations\n",
    "    for num_mutations in range(1, max_mutations + 1):\n",
    "        similarity = 1 - num_mutations/len(sequence)\n",
    "        for positions in combinations(range(len(sequence)), num_mutations):\n",
    "            # For each combination of positions, generate the possible mutations\n",
    "            mutation_indices = [range(1, 5)] * num_mutations\n",
    "            for mutation_combination in product(*mutation_indices):\n",
    "                mutations = list(zip(positions, mutation_combination))\n",
    "                mutated_sequence = apply_mutations(sequence, mutations)\n",
    "                mutated_sequences.append((mutated_sequence, num_mutations, similarity))\n",
    "    \n",
    "    return mutated_sequences\n",
    "\n",
    "# Example usage\n",
    "true_negative_samples = pd.read_csv(\"true_negative_samples.csv\")\n",
    "mutated_sequences_with_mutations = mutate_sequence(true_negative_samples['sequence'][0], max_mutations=math.ceil(0.2*len(true_negative_samples['sequence'][0])))\n",
    "print(mutated_sequences_with_mutations)\n",
    "\n",
    "df = pd.DataFrame(mutated_sequences_with_mutations, columns=['Mutated Sequence', 'Number of Mutations', 'Similarity'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mut_peptides_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mut_data, _, _, mut_loader \u001b[38;5;241m=\u001b[39m read_predict_data(\u001b[43mmut_peptides_df\u001b[49m, batch_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mut_peptides_df' is not defined"
     ]
    }
   ],
   "source": [
    "mut_data, _, _, mut_loader = read_predict_data(mut_peptides_df, batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
